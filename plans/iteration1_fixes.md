# План исправления ошибок - Итерация 1

## Контекст
Согласно TODO.md, Итерация 1 включает исправления без изменения логики поиска:
1. Исправить критичный баг в run_parse (формат пары в не‑test режиме)
2. Добавить timeout в requests (html_fragment.extract_common_parent_from_url, debug_selectors.run_search)
3. Удалить вводящий «pass» в extract_value и уточнить поведение
4. Исправить аннотации типов в тестовых данных и generate_pattern

## Детальный план

### 1. Исправление критичного бага в run_parse

**Проблема**: В функции `run_parse` в не-test режиме создается структура `{url: [(label, value)]}` (кортеж), но далее код ожидает словарь с ключами 'label' и 'value' (строка 615: `pair['label']`).

**Решение**:
- Изменить формат пары на словарь: `{'label': args.label, 'value': args.value}`
- Обновить обработку в цикле для поддержки обоих форматов (обратная совместимость)
- Обновить аннотации типов

**Подзадачи**:
1.1. Найти точное место бага в `debug_selectors.py:run_parse`
1.2. Изменить строку 595: `{args.url: [(args.label, args.value)]}` → `{args.url: [{'label': args.label, 'value': args.value}]}`
1.3. Проверить, что функция `search_web` ожидает параметры `label` и `value` как строки (а не как словарь)
1.4. Убедиться, что тестовый режим также использует словари (уже использует)
1.5. Обновить аннотацию возвращаемого значения функции `run_parse`

### 2. Добавление timeout в requests

#### 2.1. Для `html_fragment.extract_common_parent_from_url`

**Проблема**: Отсутствует timeout у `requests.get` — возможны зависания.

**Решение**:
- Добавить параметр `timeout` в функцию `extract_common_parent_from_url`
- Использовать значение по умолчанию из `ScraperConfig` (например, `page_load_timeout`)
- Обрабатывать `RequestException` и `Timeout`

**Подзадачи**:
2.1.1. Добавить параметр `timeout` в сигнатуру функции (по умолчанию `None`)
2.1.2. В теле функции передать `timeout` в `requests.get(**kwargs)`
2.1.3. Добавить обработку исключений `requests.exceptions.Timeout` и `requests.exceptions.RequestException`
2.1.4. Обновить вызовы этой функции в других модулях (например, в `debug_selectors.search_web`)

#### 2.2. Для `debug_selectors.run_search`

**Проблема**: Прямой `requests.get` без timeout и без объединения заголовков.

**Решение**:
- Добавить timeout (из ScraperConfig)
- Использовать согласованные заголовки из `html_fragment.DEFAULT_HEADERS`
- Обрабатывать RequestException с понятным логом

**Подзадачи**:
2.2.1. Найти функцию `run_search` в `debug_selectors.py`
2.2.2. Добавить импорт `ScraperConfig` и `DEFAULT_HEADERS`
2.2.3. Модифицировать вызов `requests.get` с параметрами `timeout` и `headers`
2.2.4. Добавить обработку исключений

### 3. Удаление вводящего «pass» в extract_value

**Проблема**: В ветке XPath/lxml есть комментарий «pass» в строке 528, который вводит в заблуждение.

**Решение**:
- Удалить комментарий `pass`
- Явно описать поведение: берем `elements[0]`, текст через `string()`, атрибуты — `element.get(name)`
- Уточнить типы (возвращает `Optional[str]`)

**Подзадачи**:
3.1. Найти строку с `pass` в `extract_value`
3.2. Заменить комментарий на явное описание логики
3.3. Проверить, что код после `pass` корректен (строки 530-568)
3.4. Обновить докстринг функции

### 4. Исправление аннотаций типов

#### 4.1. Тестовые данные (`get_test_data_to_parse` / `get_test_data_to_search`)

**Проблема**: Неверные аннотации типов (указаны `dict[str, list[tuple[str,str]]]`, фактически возвращают `List[Dict[label,value]]`).

**Решение**:
- Исправить сигнатуру на `Dict[str, List[Dict[str, str]]]`
- Рассмотреть введение `TypedDict` (LabelValuePair)

**Подзадачи**:
4.1.1. Обновить аннотации в обеих функциях
4.1.2. Проверить, что возвращаемые значения соответствуют новым аннотациям
4.1.3. Обновить все места использования этих функций

#### 4.2. Функция `generate_pattern`

**Проблема**: Некорректные аннотации (`parse_frags: str;` → возвращает `List[Dict]`, а объявлен `Dict`).

**Решение**:
- Исправить типы: вход — `Iterable[Tuple[url, label, value, List[str], Optional[dict]]]`, выход — `List[Dict[str, Any]]`
- Обновить докстринг

**Подзадачи**:
4.2.1. Исправить аннотацию параметра `parse_frags`
4.2.2. Исправить аннотацию возвращаемого значения
4.2.3. Проверить, что внутренняя логика соответствует типам

## Дополнительные задачи

### 5. Обновление CONCEPTION.md
- Добавить раздел об изменениях в Итерации 1
- Обновить документацию по таймаутам и обработке ошибок
- Указать новые типы данных

### 6. Запись в PROGRESS.md
- Добавить запись о выполнении Итерации 1
- Указать исправленные баги и добавленные улучшения

### 7. Проверка кода
- Запустить `ruff check .` для проверки стиля и ошибок
- Запустить `ruff format` для автоматического форматирования
- Убедиться, что тесты проходят

## Приоритет выполнения
1. Критичный баг в run_parse (блокирует работу)
2. Добавление timeout (улучшение стабильности)
3. Исправление аннотаций типов (улучшение читаемости)
4. Удаление вводящего pass (косметическое улучшение)

## Ожидаемые результаты
После выполнения Итерации 1:
- Скрипт `debug_selectors.py` будет работать корректно в не-test режиме
- Запросы HTTP будут иметь таймауты, предотвращая зависания
- Аннотации типов будут точными, улучшая поддержку IDE
- Код будет более читаемым и понятным