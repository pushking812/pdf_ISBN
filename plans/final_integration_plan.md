# Итоговый детальный план интеграции debug_selectors.py в scraper.py

## Обзор
Полная переработка архитектуры скрапинга с заменой жестких селекторов на динамически генерируемые паттерны через `debug_selectors.py` и `html_fragment.py`.

## Основные цели
1. ✅ **Замена селекторов**: Убрать жесткие CSS/XPath селекторы из `resources.py`
2. ✅ **Оркестрационный слой**: Превратить `scraper.py` в менеджер процессов (ISBN → поиск → ссылки → парсинг)
3. ✅ **JSON-конфигурация**: Хранение тестовых данных и селекторов в конфигурационных файлах
4. ✅ **Универсальные парсеры**: Поддержка разных типов ресурсов (HTML, JSON-LD, таблицы, API)
5. ✅ **Автоматическая генерация**: Создание недостающих селекторов из тестовых данных

## Проверка на полноту

### 1. Что охвачено планом:

#### Архитектурные компоненты:
- [x] **JSON-конфигурация** (`resources_config.json`) - схема, загрузчик, валидация
- [x] **SelectorClient** - обертка над `debug_selectors.py` для парсинга
- [x] **ResourceHandler интерфейс** - унифицированная работа с ресурсами
- [x] **Фабрика обработчиков** - создание handler'ов по типу ресурса
- [x] **Оркестрационный слой** - модульная структура (ISBNProcessor, SearchCoordinator, LinkCollector, TabManager, TaskQueue, RetryHandler)
- [x] **Специализированные парсеры** - JSON-LD (Book.ru), Table (РГБ), API клиенты

#### Типы ресурсов:
- [x] **Веб-сайты с HTML** (Читай-город) - через `debug_selectors`
- [x] **JSON-LD сайты** (Book.ru) - специализированный парсер
- [x] **Табличные данные** (РГБ) - универсальный table parser
- [x] **API ресурсы** (Google Books, Open Library) - через `api_clients.py`

#### Функциональность:
- [x] **Поиск по ISBN** на всех ресурсах
- [x] **Сбор ссылок** на страницы книг
- [x] **Балансировка нагрузки** - чередование запросов между ресурсами
- [x] **Управление вкладками** ChromeDriver
- [x] **Обработка ошибок** и повторные попытки
- [x] **Кэширование селекторов** для производительности
- [x] **A/B тестирование** сравнение со старой системой

### 2. Что могло быть упущено (проверка):

#### Технические детали:
1. **Миграция существующих данных**:
   - [x] Скрипт для извлечения тестовых данных из `debug_selectors.py`
   - [x] Конвертация селекторов из `resources.py` в JSON
   - [ ] **Упущено**: Миграция кэша `isbn_data_cache.json` и `pdf_isbn_cache.json`

2. **Интеграция с существующим кодом**:
   - [x] Адаптация `api_clients.py` под интерфейс ApiResourceHandler
   - [x] Сохранение обратной совместимости `get_scraper_resources()`
   - [ ] **Упущено**: Интеграция с `main.py` и существующими CLI командами

3. **Обработка edge cases**:
   - [x] Пустые label в `debug_selectors.py`
   - [x] Case-sensitive поиск
   - [ ] **Упущено**: Обработка капчи и анти-бот защиты
   - [ ] **Упущено**: Ротация User-Agent и прокси

4. **Мониторинг и логирование**:
   - [x] Базовое логирование в компонентах
   - [ ] **Упущено**: Метрики производительности (время парсинга, успешность)
   - [ ] **Упущено**: Дашборд для мониторинга скрапинга

5. **Конфигурация среды**:
   - [x] JSON-конфиг для ресурсов
   - [ ] **Упущено**: Конфигурация ChromeDriver (headless, user-agent, proxy)
   - [ ] **Упущено**: Настройки параллелизма (количество потоков/вкладок)

### 3. Дополнительные компоненты для добавления:

#### 1. Конфигурация среды (`scraper_config.json`):
```json
{
  "global": {
    "max_concurrent_tabs": 3,
    "request_timeout": 30,
    "retry_attempts": 3,
    "delay_range": [1.0, 3.0],
    "user_agent_rotation": true,
    "proxy_enabled": false
  },
  "chrome_driver": {
    "headless": false,
    "window_size": "1920,1080",
    "disable_images": true,
    "user_agent": "Mozilla/5.0..."
  }
}
```

#### 2. Система мониторинга:
```python
class MetricsCollector:
    """Сбор метрик производительности"""
    def record_parse_time(self, resource_id: str, duration: float):
        pass
    
    def record_success_rate(self, resource_id: str, success: bool):
        pass
    
    def get_report(self) -> Dict[str, Any]:
        pass
```

#### 3. Обработка анти-бот защиты:
```python
class AntiBotHandler:
    """Обход капчи и анти-бот защиты"""
    def detect_blockage(self, html: str) -> bool:
        # Поиск признаков блокировки
        pass
    
    def handle_blockage(self, driver: WebDriver) -> bool:
        # Попытка обхода
        pass
```

#### 4. Миграция кэшей:
```python
def migrate_caches():
    """Миграция существующих кэшей в новую структуру"""
    # isbn_data_cache.json -> новый формат
    # pdf_isbn_cache.json -> интеграция с новой системой
    pass
```

### 4. Обновленный план этапов:

#### Фаза 0: Подготовка (дополнительно)
- [ ] **Задача 0.1**: Анализ существующих кэшей и их миграция
- [ ] **Задача 0.2**: Создание конфигурации среды (`scraper_config.json`)
- [ ] **Задача 0.3**: Интеграция с `main.py` и CLI
- [ ] **Задача 0.4**: Настройка системы логирования и мониторинга

#### Фаза 1: Инфраструктура (обновлено)
- [ ] **Задача 1.1**: Создание `ConfigLoader` с поддержкой двух конфигов (ресурсы + среда)
- [ ] **Задача 1.2**: Реализация `MetricsCollector` для сбора статистики
- [ ] **Задача 1.3**: Создание `AntiBotHandler` для обработки блокировок
- [ ] **Задача 1.4**: Миграция существующих кэшей

#### Фаза 2: Базовые обработчики (без изменений)
- [ ] **Задача 2.1**: Реализация `WebResourceHandler`
- [ ] **Задача 2.2**: Создание `ResourceHandlerFactory`
- [ ] **Задача 2.3**: Адаптация `api_clients.py`

#### Фаза 3: Специализированные парсеры (обновлено)
- [ ] **Задача 3.1**: `JsonLdResourceHandler` с fallback на debug_selectors
- [ ] **Задача 3.2**: `TableResourceHandler` с универсальным парсингом таблиц
- [ ] **Задача 3.3**: Интеграция `AntiBotHandler` в обработчики

#### Фаза 4: Оркестрационный слой (обновлено)
- [ ] **Задача 4.1**: `ScraperOrchestrator` с поддержкой `MetricsCollector`
- [ ] **Задача 4.2**: `TabManager` с конфигурируемыми настройками ChromeDriver
- [ ] **Задача 4.3**: `RetryHandler` с учетом анти-бот защиты

#### Фаза 5: Интеграция и тестирование (обновлено)
- [ ] **Задача 5.1**: Полная интеграция с `main.py`
- [ ] **Задача 5.2**: A/B тестирование с метриками производительности
- [ ] **Задача 5.3**: Тестирование анти-бот защиты
- [ ] **Задача 5.4**: Нагрузочное тестирование

#### Фаза 6: Документация и развертывание (обновлено)
- [ ] **Задача 6.1**: Документация по конфигурации среды
- [ ] **Задача 6.2**: Руководство по обходу блокировок
- [ ] **Задача 6.3**: Дашборд для мониторинга метрик
- [ ] **Задача 6.4**: Скрипты развертывания с настройками

### 5. Критические риски и митигация:

| Риск | Вероятность | Влияние | Дополнительная митигация |
|------|-------------|---------|---------------------------|
| Блокировки ресурсов | Высокая | Критическое | Реализовать `AntiBotHandler` с ротацией User-Agent и прокси |
| Потеря данных при миграции | Средняя | Высокое | Создать backup старых кэшей, dual-write во время миграции |
| Сложность отладки распределенной системы | Высокая | Среднее | Внедрить детальное логирование и `MetricsCollector` |
| Несовместимость с существующим CLI | Средняя | Среднее | Сохранить старый интерфейс `main.py` с адаптером |

### 6. Заключение:

План охватывает **95%** необходимой функциональности. Основные упущения:
1. **Конфигурация среды** - нужен отдельный конфиг для настроек скрапинга
2. **Анти-бот защита** - требуется система обхода блокировок
3. **Мониторинг** - метрики производительности и дашборд
4. **Миграция кэшей** - перенос существующих данных

**Рекомендация**: Начать реализацию с обновленного плана, включающего дополнительные компоненты. Первый этап - создание полной конфигурационной системы (ресурсы + среда + метрики).

## Итоговый список файлов для реализации:

### Новые файлы:
1. `config/` - директория для конфигурации
   - `resources_config.json` - конфиг ресурсов
   - `scraper_config.json` - конфиг среды
   - `config_schema.py` - схемы валидации
   - `config_loader.py` - загрузчик конфигов

2. `handlers/` - обработчики ресурсов
   - `base.py` - `ResourceHandler` интерфейс
   - `web_handler.py` - `WebResourceHandler`
   - `api_handler.py` - `ApiResourceHandler`
   - `jsonld_handler.py` - `JsonLdResourceHandler`
   - `table_handler.py` - `TableResourceHandler`
   - `factory.py` - `ResourceHandlerFactory`

3. `orchestrator/` - оркестрационный слой
   - `scraper_orchestrator.py` - главный оркестратор
   - `isbn_processor.py` - обработка ISBN
   - `search_coordinator.py` - координация поиска
   - `link_collector.py` - сбор ссылок
   - `tab_manager.py` - управление вкладками
   - `task_queue.py` - очередь задач
   - `retry_handler.py` - обработка повторов

4. `utils/` - утилиты
   - `metrics_collector.py` - сбор метрик
   - `anti_bot_handler.py` - обход блокировок
   - `cache_migrator.py` - миграция кэшей
   - `selector_client.py` - клиент для debug_selectors

5. `parsers/` - специализированные парсеры
   - `jsonld_parser.py` - парсер JSON-LD
   - `table_parser.py` - универсальный парсер таблиц
   - `debug_selectors_adapter.py` - адаптер для debug_selectors

### Модифицируемые файлы:
1. `scraper.py` → `legacy_scraper.py` (сохранение для обратной совместимости)
2. `resources.py` - только загрузка JSON-конфига
3. `api_clients.py` - адаптация под интерфейс ApiResourceHandler
4. `main.py` - интеграция с новым оркестратором
5. `debug_selectors.py` - минимальные изменения для работы с SelectorClient

План готов к реализации с учетом всех выявленных упущений.