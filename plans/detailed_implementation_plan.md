# Детальный план доработки архитектуры скрапинга

## Обзор
План разбит на 4 итерации, каждая из которых фокусируется на конкретных компонентах и функциональности. Каждая итерация рассчитана на 1-2 недели работы.

## Итерация A: Завершение базового оркестрационного слоя

### Цель
Реализовать недостающие компоненты оркестрационного слоя для обеспечения работоспособности скрапинга.

### Подзадачи

#### A.1. SearchCoordinator (Координатор поиска)
**Назначение**: Координация поиска между ресурсами, определение приоритетов, распределение задач.
- [ ] **A.1.1**: Создать класс `SearchCoordinator` в `scraper_core/orchestrator/search.py`
- [ ] **A.1.2**: Реализовать стратегию приоритизации ресурсов (на основе успешности, скорости)
- [ ] **A.1.3**: Добавить балансировку нагрузки между ресурсами
- [ ] **A.1.4**: Интегрировать с `ScraperOrchestrator.task_queue`
- [ ] **A.1.5**: Написать тесты для `SearchCoordinator`

#### A.2. LinkCollector (Сборщик ссылок)
**Назначение**: Сбор и валидация ссылок на страницы книг.
- [ ] **A.2.1**: Создать класс `LinkCollector` в `scraper_core/orchestrator/links.py`
- [ ] **A.2.2**: Реализовать извлечение ссылок из результатов поиска
- [ ] **A.2.3**: Добавить фильтрацию дубликатов и валидацию URL
- [ ] **A.2.4**: Интегрировать с `WebResourceHandler`
- [ ] **A.2.5**: Написать тесты для `LinkCollector`

#### A.3. TaskQueue с приоритетами
**Назначение**: Управление очередями задач с поддержкой приоритетов.
- [ ] **A.3.1**: Расширить существующую `asyncio.Queue` в `ScraperOrchestrator`
- [ ] **A.3.2**: Реализовать приоритеты задач (высокий для API, средний для веб, низкий для повторных попыток)
- [ ] **A.3.3**: Добавить механизм чередования ресурсов для избежания блокировок
- [ ] **A.3.4**: Реализовать статистику выполнения задач
- [ ] **A.3.5**: Написать тесты для системы очередей

#### A.4. Интеграция компонентов
- [ ] **A.4.1**: Обновить `ScraperOrchestrator` для использования новых компонентов
- [ ] **A.4.2**: Настроить взаимодействие между `SearchCoordinator`, `LinkCollector` и `TaskQueue`
- [ ] **A.4.3**: Протестировать полный цикл с тестовыми данными
- [ ] **A.4.4**: Исправить выявленные ошибки интеграции

### Выходные артефакты
- Рабочие модули: `SearchCoordinator`, `LinkCollector`, расширенная `TaskQueue`
- Интегрированный оркестратор с поддержкой приоритетов и балансировки
- Тестовое покрытие для новых компонентов

## Итерация B: Управление вкладками и обработка ошибок

### Цель
Реализовать управление вкладками браузера и систему обработки ошибок/повторных попыток.

### Подзадачи

#### B.1. TabManager (Менеджер вкладок)
**Назначение**: Управление вкладками браузера на основе логики `async_parallel_search`.
- [ ] **B.1.1**: Создать класс `TabManager` в `scraper_core/orchestrator/tabs.py`
- [ ] **B.1.2**: Адаптировать логику из `async_parallel_search` (из `scraper.py`)
- [ ] **B.1.3**: Реализовать пул вкладок с ограничением `max_concurrent_tabs`
- [ ] **B.1.4**: Добавить мониторинг состояния вкладок (TabState)
- [ ] **B.1.5**: Интегрировать с `DriverManager` (будущим)

#### B.2. RetryHandler (Обработчик повторных попыток)
**Назначение**: Обработка ошибок и повторных попыток с экспоненциальным backoff.
- [ ] **B.2.1**: Создать класс `RetryHandler` в `scraper_core/orchestrator/retry.py`
- [ ] **B.2.2**: Реализовать стратегии повторных попыток для разных типов ошибок
- [ ] **B.2.3**: Добавить экспоненциальный backoff с джиттером
- [ ] **B.2.4**: Интегрировать с `ScraperOrchestrator` и обработчиками ресурсов
- [ ] **B.2.5**: Написать тесты для `RetryHandler`

#### B.3. DriverManager (Менеджер драйверов)
**Назначение**: Централизованное управление Selenium WebDriver.
- [ ] **B.3.1**: Создать класс `DriverManager` в `scraper_core/drivers/manager.py`
- [ ] **B.3.2**: Адаптировать код из существующего `drivers.py`
- [ ] **B.3.3**: Реализовать пул драйверов для повторного использования
- [ ] **B.3.4**: Добавить настройки из `ScraperEnvConfig` (headless, timeout, user-agent)
- [ ] **B.3.5**: Интегрировать с `TabManager` и `WebResourceHandler`

#### B.4. AntiBotHandler (Обработчик анти-бот защиты)
**Назначение**: Обход блокировок и обнаружение анти-бот защиты.
- [ ] **B.4.1**: Создать класс `AntiBotHandler` в `scraper_core/utils/anti_bot.py`
- [ ] **B.4.2**: Реализовать обнаружение блокировок по ключевым фразам
- [ ] **B.4.3**: Добавить стратегии обхода (задержки, смена user-agent, использование прокси)
- [ ] **B.4.4**: Интегрировать с `WebResourceHandler` и `DriverManager`
- [ ] **B.4.5**: Написать тесты для `AntiBotHandler`

### Выходные артефакты
- Рабочие модули: `TabManager`, `RetryHandler`, `DriverManager`, `AntiBotHandler`
- Полноценное управление вкладками браузера
- Надежная система обработки ошибок и повторных попыток
- Базовые механизмы обхода анти-бот защиты

## Итерация C: Интеграция и миграция данных

### Цель
Интегрировать новую архитектуру с существующим кодом и начать миграцию данных.

### Подзадачи

#### C.1. Полная интеграция html_fragment.py
- [ ] **C.1.1**: Вынести функции из `html_fragment.py` в `scraper_core/parsers/html.py`
- [ ] **C.1.2**: Создать адаптер для обратной совместимости `html_fragment.py`
- [ ] **C.1.3**: Обновить `SelectorClient` для использования нового модуля
- [ ] **C.1.4**: Протестировать совместимость с существующим кодом

#### C.2. Dual-write в старые кэши
- [ ] **C.2.1**: Реализовать dual-write в `isbn_data_cache.json`
- [ ] **C.2.2**: Реализовать dual-write в `pdf_isbn_cache.json`
- [ ] **C.2.3**: Добавить валидацию согласованности данных
- [ ] **C.2.4**: Создать скрипт миграции старых данных в новый формат

#### C.3. A/B тестирование
- [ ] **C.3.1**: Настроить параллельный запуск старой и новой системы
- [ ] **C.3.2**: Реализовать сбор метрик производительности
- [ ] **C.3.3**: Сравнить результаты и точность данных
- [ ] **C.3.4**: Выявить и исправить расхождения

#### C.4. Документация и руководства
- [ ] **C.4.1**: Обновить `MIGRATION_GUIDE.md` с инструкциями по переходу
- [ ] **C.4.2**: Создать документацию API новой системы
- [ ] **C.4.3**: Написать руководство по конфигурации ресурсов
- [ ] **C.4.4**: Обновить `CONCEPTION.md` с новой архитектурой

### Выходные артефакты
- Полностью интегрированная система с обратной совместимостью
- Dual-write система для плавной миграции
- Результаты A/B тестирования
- Полная документация

## Итерация D: Оптимизация и production-готовность

### Цель
Оптимизация производительности и подготовка к production-развертыванию.

### Подзадачи

#### D.1. Оптимизация кэширования
- [ ] **D.1.1**: Реализовать LRU кэш для селекторов в `scraper_core/utils/cache.py`
- [ ] **D.1.2**: Добавить кэширование результатов парсинга
- [ ] **D.1.3**: Реализовать инвалидацию кэша по времени и изменению данных
- [ ] **D.1.4**: Настроить кэширование HTTP-запросов

#### D.2. Система метрик и мониторинга
- [ ] **D.2.1**: Создать `MetricsCollector` в `scraper_core/utils/metrics.py`
- [ ] **D.2.2**: Реализовать сбор метрик: успешность, время ответа, ошибки
- [ ] **D.2.3**: Добавить экспорт метрик в формате для дашбордов
- [ ] **D.2.4**: Настроить базовый алертинг по ключевым метрикам

#### D.3. Производственные улучшения
- [ ] **D.3.1**: Реализовать поддержку прокси и ротации user-agent
- [ ] **D.3.2**: Добавить health-check эндпоинты
- [ ] **D.3.3**: Реализовать graceful shutdown
- [ ] **D.3.4**: Настроить логирование в структурированном формате (JSON)

#### D.4. Тестирование и надежность
- [ ] **D.4.1**: Провести нагрузочное тестирование с большими объемами ISBN
- [ ] **D.4.2**: Тестирование отказоустойчивости (сетевые ошибки, блокировки)
- [ ] **D.4.3**: Реализовать chaos-тестирование ключевых компонентов
- [ ] **D.4.4**: Достичь 80% покрытия кода тестами

### Выходные артефакты
- Оптимизированная система с кэшированием
- Система метрик и мониторинга
- Production-готовое решение
- Результаты нагрузочного тестирования

## Приоритеты и зависимости

### Критические зависимости
1. **Итерация A** должна быть завершена перед началом Итерации B
2. **DriverManager** (B.3) требуется для работы **TabManager** (B.1)
3. **Интеграция html_fragment.py** (C.1) требуется для полной функциональности парсинга

### Рекомендуемая последовательность
1. Завершить **Итерацию A** (2-3 недели)
2. Параллельно начать **Итерацию B** и **Итерацию C** (3-4 недели)
3. Завершить **Итерацию D** (2-3 недели)

## Недостающая информация для реализации

### Требуемая информация
1. **Детали логики `async_parallel_search`**: 
   - Точный алгоритм управления вкладками
   - Стратегии переключения между ресурсами
   - Обработка таймаутов и ошибок

2. **Структура старых кэшей**:
   - Формат `isbn_data_cache.json`
   - Формат `pdf_isbn_cache.json`
   - Правила валидации и обновления

3. **Требования к production**:
   - Ожидаемая нагрузка (количество ISBN в день)
   - Требования к доступности и надежности
   - Интеграция с существующей инфраструктурой

4. **Детали анти-бот защиты**:
   - Список ресурсов с сильной защитой
   - Эффективные стратегии обхода для каждого ресурса
   - Ограничения по частоте запросов

### Способы получения информации
1. **Анализ кода**: Изучение `scraper.py`, `async_parallel_search`, `drivers.py`
2. **Тестирование**: Запуск существующей системы и сбор метрик
3. **Консультация**: Обсуждение с разработчиками существующего кода
4. **Эксперименты**: Тестирование различных стратегий на реальных ресурсах

## Оценка усилий

### Итерация A: 2-3 недели
- SearchCoordinator: 3-4 дня
- LinkCollector: 2-3 дня  
- TaskQueue: 2-3 дня
- Интеграция: 3-4 дня

### Итерация B: 3-4 недели
- TabManager: 4-5 дней
- RetryHandler: 2-3 дня
- DriverManager: 3-4 дня
- AntiBotHandler: 3-4 дня

### Итерация C: 2-3 недели
- Интеграция html_fragment: 3-4 дня
- Dual-write: 3-4 дня
- A/B тестирование: 4-5 дней
- Документация: 2-3 дня

### Итерация D: 2-3 недели
- Оптимизация кэширования: 3-4 дня
- Система метрик: 4-5 дней
- Production улучшения: 3-4 дня
- Тестирование: 4-5 дней

**Итого**: 9-13 недель для полной реализации.

## Риски и митигация

### Риск 1: Сложность интеграции с существующим кодом
**Митигация**: Поэтапная интеграция, extensive testing, сохранение обратной совместимости

### Риск 2: Блокировки со стороны ресурсов
**Митигация**: Реализация продвинутых стратегий AntiBotHandler, использование прокси

### Риск 3: Производительность при больших объемах
**Митигация**: Оптимизация кэширования, асинхронная архитектура, нагрузочное тестирование

### Риск 4: Недостаток информации о бизнес-логике
**Митигация**: Активный анализ кода, консультации с экспертами, итеративный подход

## Заключение

План обеспечивает систематический подход к доработке архитектуры скрапинга. Рекомендуется начать с Итерации A для создания рабочего ядра оркестрационного слоя, затем параллельно работать над Итерациями B и C для добавления функциональности и интеграции. Итерация D завершит оптимизацию для production-готовности.

Ключевой успех зависит от тщательного тестирования каждой итерации и активного сбора обратной связи от существующей системы.