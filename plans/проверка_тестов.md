# Проверка тестов на реальных данных (isbn_list.txt)

## Цель
Убедиться, что созданные тесты работают корректно с реальными ISBN из файла `isbn_list.txt`. Проверить, что каждый ресурс возвращает данные хотя бы для одного ISBN.

## Подготовка
1. Убедиться, что файл `isbn_list.txt` существует и содержит валидные ISBN.
2. Проверить, что тестовые файлы созданы в директории `tests/`.
3. Установить все зависимости (pytest, pytest-asyncio, selenium, webdriver-manager и т.д.).

## Шаги проверки

### 1. Запуск синхронных тестов API
```bash
pytest tests/test_api_clients_sync.py -v
```
Ожидаемый результат:
- Тесты для Google Books, Open Library, РГБ должны пройти (или быть пропущены, если ни один ISBN не дал результат).
- В логах должно быть видно, для какого ISBN получен успех.

### 2. Запуск асинхронных тестов API
```bash
pytest tests/test_api_clients_async.py -v
```
Ожидаемый результат аналогичен синхронным тестам.

### 3. Запуск тестов скраперов
```bash
pytest tests/test_scrapers.py -v
```
Ожидаемый результат:
- Тесты для Читай-город и Book.ru проходят (или пропускаются, если товары не найдены).
- Браузер запускается в headless-режиме.
- Не должно быть критических ошибок (таймауты, отсутствие элементов).

### 4. Анализ результатов
- Если тест проходит: ресурс работает корректно.
- Если тест пропускается (skip): ни один ISBN не дал результата. Это может быть из-за отсутствия книги в каталоге ресурса, блокировки или изменений в сайте.
- Если тест падает с ошибкой: необходимо исправить код теста или логику работы ресурса.

## Возможные проблемы и решения

### Проблема 1: Все тесты пропускаются
Причина: возможно, ISBN в списке невалидны или ресурсы не содержат таких книг.
Решение:
- Проверить валидность ISBN (нормализация).
- Добавить более популярные ISBN для тестирования (например, 9785171621988).
- Вручную проверить работу ресурса через браузер или curl.

### Проблема 2: Сетевая ошибка (таймаут, соединение)
Причина: медленная сеть или блокировка.
Решение:
- Увеличить таймауты в функциях API клиентов.
- Добавить повторные попытки (retry).
- Пропустить тест, если ошибка временная.

### Проблема 3: Браузерные тесты падают из-за изменений вёрстки
Причина: сайты изменили структуру, селекторы устарели.
Решение:
- Обновить селекторы в `resources.py`.
- Использовать более устойчивые селекторы (например, по data-атрибутам).
- Добавить fallback-селекторы.

### Проблема 4: Асинхронные тесты падают из-за цикла событий
Причина: неправильная настройка asyncio.
Решение:
- Убедиться, что используется `pytest.mark.asyncio`.
- В `conftest.py` правильно создаётся и закрывается сессия.

## Действия после проверки

### Успешная проверка
- Зафиксировать результаты в отчёте.
- Добавить автоматический запуск тестов в CI.

### Неуспешная проверка
- Определить, какие ресурсы не работают.
- Принять решение: исправить ресурсы или исключить их из тестов.
- Обновить тесты, чтобы они были более устойчивыми.

## Отчёт о проверке
Создать файл `test_report.md` с результатами проверки:
- Дата и время запуска.
- Количество успешных, пропущенных, упавших тестов.
- Для каждого ресурса: ISBN, который сработал, или причина пропуска.
- Рекомендации по улучшению.

## Следующие шаги
1. Запустить тесты и собрать результаты.
2. Создать отчёт.
3. При необходимости доработать тесты.
4. Интегрировать тесты в процесс разработки (pre-commit hook, CI).