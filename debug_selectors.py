#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é –º–æ–¥—É–ª—è html_fragment.

–ü–æ–∑–≤–æ–ª—è–µ—Ç –±—ã—Å—Ç—Ä–æ –ø–æ–ª—É—á–∏—Ç—å HTML-—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –ø–∞—Ä—É ¬´–Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è ‚Äì –∑–Ω–∞—á–µ–Ω–∏–µ¬ª,
—á—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –≤ —Ä—É—á–Ω–æ–º –ø–æ–¥–±–æ—Ä–µ CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python debug_selectors.py <URL> <label_text> <value_text> [--selenium] [--exact] [--case-sensitive]

–ü—Ä–∏–º–µ—Ä:
    python debug_selectors.py https://example.com/book "–ì–æ–¥ –∏–∑–¥–∞–Ω–∏—è" "2020"
"""

import sys
import time
import argparse
import random
from typing import Optional
from selenium.webdriver.remote.webdriver import WebDriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By

from html_fragment import (
    extract_common_parent_from_url,
    extract_common_parent_from_driver,
    find_elements_by_text,
    find_text_nodes,
    lowest_common_ancestor,
)
from bs4 import BeautifulSoup, Tag
from typing import Dict, Any, Union, Iterable, Tuple, List
from resources import get_resource_by_url
from config import ScraperConfig


def parse_arguments(
    url: str,
    label: str,
    value: str,
    selenium: bool,
    exact: bool,
    verbose: bool,
    test: bool,
    search_mode: str,
    case_sensitive: bool = False,
    all_matches: bool = False,
) -> argparse.Namespace:
    """–ü–∞—Ä—Å–∏—Ç –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Å –Ω–∏–º–∏."""
    parser = argparse.ArgumentParser(
        description="–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ HTML-—Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –ø–æ –ø–∞—Ä–µ ¬´–Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è ‚Äì –∑–Ω–∞—á–µ–Ω–∏–µ¬ª."
    )
    parser.add_argument(
        "url",
        help="URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã",
        nargs="?",
        default=url,
    )
    parser.add_argument(
        "label",
        help="–¢–µ–∫—Å—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, '–ì–æ–¥ –∏–∑–¥–∞–Ω–∏—è')",
        nargs="?",
        default=label,
    )
    parser.add_argument(
        "value",
        help="–¢–µ–∫—Å—Ç –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ª—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, '2020')",
        nargs="?",
        default=value,
    )
    parser.add_argument(
        "--selenium",
        action="store_true",
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Selenium WebDriver (–¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü)",
        default=selenium,
    )
    parser.add_argument(
        "--exact",
        action="store_true",
        help="–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äì —á–∞—Å—Ç–∏—á–Ω–æ–µ)",
        default=exact,
    )
    parser.add_argument(
        "--case-sensitive",
        action="store_true",
        help="–£—á–∏—Ç—ã–≤–∞—Ç—å —Ä–µ–≥–∏—Å—Ç—Ä (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äì –Ω–µ—Ç)",
        default=case_sensitive,
    )
    parser.add_argument(
        "--all-matches",
        action="store_true",
        help="–ü–æ–∫–∞–∑–∞—Ç—å –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äì —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π)",
        default=all_matches,
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="–í—ã–≤–æ–¥–∏—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é",
        default=verbose,
    )
    parser.add_argument(
        "--test",
        action="store_true",
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (–∂—ë—Å—Ç–∫–æ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ URL –∏ –ø–∞—Ä—ã)",
        default=test,
    )
    parser.add_argument(
        "--search-mode",
        choices=["text", "element"],
        default=search_mode,
        help="–†–µ–∂–∏–º –ø–æ–∏—Å–∫–∞ —É–∑–ª–æ–≤: text (–ø–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–º —É–∑–ª–∞–º), element (–ø–æ —ç–ª–µ–º–µ–Ω—Ç–∞–º —Å –ø–æ–ª–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º)",
    )
    return parser.parse_args()


def get_test_data_to_parse() -> dict[str, list[dict[str, str]]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (URL -> —Å–ø–∏—Å–æ–∫ –ø–∞—Ä label-value)."""
    return {
        "https://search.rsl.ru/ru/record/01010115385": [
            {"label": "–ê–≤—Ç–æ—Ä", "value": "–ú–∞–∫–ì—Ä–∞—Ç, –ú–∞–π–∫"},
            {
                "label": "–ó–∞–≥–ª–∞–≤–∏–µ",
                "value": "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python : Python. –ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö : –ø–µ—Ä–≤—ã–π —à–∞–≥ –Ω–∞ –ø—É—Ç–∏ –∫ —É—Å–ø–µ—à–Ω–æ–π –∫–∞—Ä—å–µ—Ä–µ : –¥–ª—è –≤–µ—Ä—Å–∏–π 3.1 - 3.4 : 12+",
            },
            {"label": "–í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", "value": "–ú–æ—Å–∫–≤–∞ : –≠–∫—Å–º–æ, 2019"},
            {"label": "–§–∏–∑–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ", "value": "192 —Å. : –∏–ª.; 26 —Å–º"},
        ],
        "https://www.chitai-gorod.ru/product/programmirovanie-na-python-v-primerah-i-zadachah-2832349": [
            {"label": "", "value": "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö –∏ –∑–∞–¥–∞—á–∞—Ö"},
            {"label": "–ì–æ–¥ –∏–∑–¥–∞–Ω–∏—è", "value": "2025"},
            {"label": "", "value": "–ê–ª–µ–∫—Å–µ–π –í–∞—Å–∏–ª—å–µ–≤"},
            {"label": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü", "value": "616"},
        ],
        "https://book.ru/book/943665": [
            {"label": "", "value": "–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –Ω–∞ Python"},
            {"label": "–ì–æ–¥ –∏–∑–¥–∞–Ω–∏—è:", "value": "2022"},
            {"label": "–ê–≤—Ç–æ—Ä—ã:", "value": "–ö—Ä–∏–≤–æ–ª–∞–ø–æ–≤ –°.–Ø., –•—Ä–∏–ø—É–Ω–æ–≤–∞ –ú.–ë."},
            {"label": "–û–±—ä–µ–º:", "value": "455 —Å—Ç—Ä."},
        ],
    }


def get_test_data_to_search() -> dict[str, list[dict[str, str]]]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (URL -> —Å–ø–∏—Å–æ–∫ –ø–∞—Ä label-value)."""
    return {
        "https://search.rsl.ru/ru/record/01010115385": [
            {"label": "–ê–≤—Ç–æ—Ä", "value": "–ú–∞–∫–ì—Ä–∞—Ç, –ú–∞–π–∫"},
            {
                "label": "–ó–∞–≥–ª–∞–≤–∏–µ",
                "value": "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python : Python. –ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö : –ø–µ—Ä–≤—ã–π —à–∞–≥ –Ω–∞ –ø—É—Ç–∏ –∫ —É—Å–ø–µ—à–Ω–æ–π –∫–∞—Ä—å–µ—Ä–µ : –¥–ª—è –≤–µ—Ä—Å–∏–π 3.1 - 3.4 : 12+",
            },
            {"label": "–í—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", "value": "–ú–æ—Å–∫–≤–∞ : –≠–∫—Å–º–æ, 2019"},
            {"label": "–§–∏–∑–∏—á–µ—Å–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ", "value": "192 —Å. : –∏–ª.; 26 —Å–º"},
        ],
        "https://www.chitai-gorod.ru/product/programmirovanie-na-python-v-primerah-i-zadachah-2832349": [
            {"label": "", "value": "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ Python –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö –∏ –∑–∞–¥–∞—á–∞—Ö"},
            {"label": "–ì–æ–¥ –∏–∑–¥–∞–Ω–∏—è", "value": "2025"},
            {"label": "", "value": "–ê–ª–µ–∫—Å–µ–π –í–∞—Å–∏–ª—å–µ–≤"},
            {"label": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü", "value": "616"},
        ],
        "https://book.ru/book/943665": [
            {"label": "", "value": "–ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –Ω–∞ Python"},
            {"label": "–ì–æ–¥ –∏–∑–¥–∞–Ω–∏—è:", "value": "2022"},
            {"label": "–ê–≤—Ç–æ—Ä—ã:", "value": "–ö—Ä–∏–≤–æ–ª–∞–ø–æ–≤ –°.–Ø., –•—Ä–∏–ø—É–Ω–æ–≤–∞ –ú.–ë."},
            {"label": "–û–±—ä–µ–º:", "value": "455 —Å—Ç—Ä."},
        ],
        "https://book.ru/book/962004": [
            {"label": "", "value": "–ú–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ Python"},
            {"label": "–ì–æ–¥ –∏–∑–¥–∞–Ω–∏—è:", "value": "2026"},
            {"label": "–ê–≤—Ç–æ—Ä—ã:", "value": "–ü–∞—Ä—à–∏–Ω—Ü–µ–≤–∞ –õ.–°., –ü–∞—Ä—à–∏–Ω—Ü–µ–≤ –ê.–ê."},
            {"label": "–û–±—ä–µ–º:", "value": "129 —Å—Ç—Ä."},
        ],
        "https://book.ru/book/960946": [
            {
                "label": "",
                "value": "–ü—Ä–∞–∫—Ç–∏–∫—É–º –∏–∑—É—á–µ–Ω–∏—è —è–∑—ã–∫–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è PYTHON. –ù–∞—á–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å",
            },
            {"label": "–ì–æ–¥ –∏–∑–¥–∞–Ω–∏—è:", "value": "2026"},
            {"label": "–ê–≤—Ç–æ—Ä—ã:", "value": "–©–µ—Ä–±–∞–∫–æ–≤ –ê.–ì."},
            {"label": "–û–±—ä–µ–º:", "value": "116 —Å—Ç—Ä."},
        ],
    }


def create_driver(headless: bool = False) -> WebDriver:
    """–°–æ–∑–¥–∞—ë—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä ChromeDriver."""
    from drivers import create_chrome_driver
    from config import ScraperConfig

    config = ScraperConfig(headless=headless)
    return create_chrome_driver(config)


def wait_for_page_with_protection(
    driver: WebDriver, timeout: int = 10, min_delay: float = 1.0, max_delay: float = 3.0
) -> None:
    """
    –û–∂–∏–¥–∞–µ—Ç –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –∞–Ω—Ç–∏-–±–æ—Ç —Å–∏—Å—Ç–µ–º.

    Args:
        driver: WebDriver —ç–∫–∑–µ–º–ø–ª—è—Ä
        timeout: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ—è–≤–ª–µ–Ω–∏—è body (—Å–µ–∫—É–Ω–¥—ã)
        min_delay: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ (—Å–µ–∫—É–Ω–¥—ã)
        max_delay: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ (—Å–µ–∫—É–Ω–¥—ã)
    """
    # –û–∂–∏–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–ø–æ—è–≤–ª–µ–Ω–∏–µ body)
    try:
        WebDriverWait(driver, timeout).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
    except Exception as e:
        print(f"[WARN] Timeout –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")

    # –°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã —Ä–µ—Å—É—Ä—Å–æ–≤
    delay = random.uniform(min_delay, max_delay)
    if delay > 0:
        time.sleep(delay)


def search_web(
    url: str,
    is_driver: bool,
    label: str,
    value: str,
    exact_label: bool,
    exact_value: bool,
    case_sensitive: bool,
    all_matches: bool,
    verbose: bool,
    search_mode: str,
    driver: Optional[WebDriver] = None,
) -> list[str]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Selenium (–µ—Å–ª–∏ is_driver=True) –∏–ª–∏ requests.
    –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω driver, –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è Selenium-–ø–æ–∏—Å–∫–∞ (is_driver –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å True).
    –ï—Å–ª–∏ driver –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω –∏ is_driver=True, —Å–æ–∑–¥–∞—ë—Ç—Å—è –Ω–æ–≤—ã–π –¥—Ä–∞–π–≤–µ—Ä, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–∫—Ä—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –ø–æ–∏—Å–∫–∞.
    """
    func = extract_common_parent_from_url
    driver_or_url = url
    created_driver = None

    if is_driver:
        if driver is not None:
            driver_or_url = driver
        else:
            created_driver = create_driver(headless=False)
            driver_or_url = created_driver
            driver_or_url.get(url)
            wait_for_page_with_protection(driver_or_url)
        func = extract_common_parent_from_driver
    else:
        # –ï—Å–ª–∏ is_driver=False, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π driver (–æ–Ω –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–µ—Ä–µ–¥–∞–Ω)
        pass

    try:
        return func(
            driver_or_url,
            label,
            value,
            exact_label=exact_label,
            exact_value=exact_value,
            case_sensitive=case_sensitive,
            all_matches=all_matches,
            verbose=verbose,
            search_mode=search_mode,
        )
    finally:
        if created_driver is not None:
            created_driver.quit()


def generate_pattern(
    parse_frags: Iterable[Tuple[str, str, str, List[str], Optional[Dict]]],
    args: argparse.Namespace,
) -> List[Dict[str, Any]]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω (CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä –∏–ª–∏ XPath) –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ª—è
    –ø–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—É HTML, —Å–æ–¥–µ—Ä–∂–∞—â–µ–º—É –ø–∞—Ä—É ¬´–∫–ª—é—á–µ–≤–æ–µ –ø–æ–ª–µ ‚Äì –∑–Ω–∞—á–µ–Ω–∏–µ¬ª.
    """
    search_mode: str = args.search_mode
    exact_label: bool = args.exact
    exact_value: bool = args.exact
    case_sensitive: bool = args.case_sensitive

    patterns = []

    def build_xpath_text_condition(
        text: str, exact: bool = False, case_sensitive: bool = False
    ) -> str:
        """
        –°—Ç—Ä–æ–∏—Ç XPath —É—Å–ª–æ–≤–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å —É—á—ë—Ç–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–±–µ–ª–æ–≤ –∏ —Ä–µ–≥–∏—Å—Ç—Ä–∞.

        Args:
            text: –ò—Å–∫–æ–º—ã–π —Ç–µ–∫—Å—Ç
            exact: –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (True) –∏–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ (False)
            case_sensitive: –£—á–∏—Ç—ã–≤–∞—Ç—å —Ä–µ–≥–∏—Å—Ç—Ä (True) –∏–ª–∏ –Ω–µ—Ç (False)

        Returns:
            XPath —É—Å–ª–æ–≤–∏–µ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ contains() –∏–ª–∏ =
        """
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∫–∞–≤—ã—á–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ
        escaped_text = text.replace("'", "'").replace('"', '"')

        if exact:
            if case_sensitive:
                # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —É—á—ë—Ç–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–∞, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–±–µ–ª–æ–≤
                return f"normalize-space(.) = '{escaped_text}'"
            else:
                # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –±–µ–∑ —É—á—ë—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º translate –¥–ª—è –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É (–∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –∏ —Ä—É—Å—Å–∫–∏–µ –±—É–∫–≤—ã)
                return f"translate(normalize-space(.), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø', 'abcdefghijklmnopqrstuvwxyz–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è') = translate('{escaped_text}', 'ABCDEFGHIJKLMNOPQRSTUVWXYZ–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø', 'abcdefghijklmnopqrstuvwxyz–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è')"
        else:
            if case_sensitive:
                # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å —É—á—ë—Ç–æ–º —Ä–µ–≥–∏—Å—Ç—Ä–∞
                return f"contains(., '{escaped_text}')"
            else:
                # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –±–µ–∑ —É—á—ë—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞
                return f"contains(translate(., 'ABCDEFGHIJKLMNOPQRSTUVWXYZ–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø', 'abcdefghijklmnopqrstuvwxyz–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è'), translate('{escaped_text}', 'ABCDEFGHIJKLMNOPQRSTUVWXYZ–ê–ë–í–ì–î–ï–Å–ñ–ó–ò–ô–ö–õ–ú–ù–û–ü–†–°–¢–£–§–•–¶–ß–®–©–™–´–¨–≠–Æ–Ø', 'abcdefghijklmnopqrstuvwxyz–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è'))"

    def get_deepest_node(nodes):
        if not nodes:
            return None

        def depth(node):
            d = 0
            while node is not None:
                node = node.parent
                d += 1
            return d

        return max(nodes, key=depth)

    def collect_unique_classes(element, ancestor):
        """
        –°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ –∫–ª–∞—Å—Å—ã —ç–ª–µ–º–µ–Ω—Ç–∞ –∏ –µ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª–µ–π (–¥–æ ancestor, –Ω–µ –≤–∫–ª—é—á–∞—è),
        –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤—ã–π –∫–ª–∞—Å—Å, —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –≤–Ω—É—Ç—Ä–∏ ancestor.
        –ï—Å–ª–∏ —Ç–∞–∫–∏—Ö –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None.
        """
        if not isinstance(element, Tag):
            element = element.parent if element.parent else element
        classes = []
        current = element
        while current is not None and current != ancestor:
            if isinstance(current, Tag) and current.has_attr("class"):
                cls = current["class"]
                if isinstance(cls, str):
                    cls = cls.split()
                if isinstance(cls, list):
                    classes.extend(cls)
            current = current.parent
        # –£–±—Ä–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
        seen = set()
        unique = []
        for cls in classes:
            if cls not in seen:
                seen.add(cls)
                unique.append(cls)
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –≤–Ω—É—Ç—Ä–∏ ancestor
        for cls in unique:
            if len(ancestor.select(f".{cls}")) == 1:
                return cls
        return None

    def are_siblings(node1, node2):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è—é—Ç—Å—è –ª–∏ –¥–≤–∞ —É–∑–ª–∞ —Å–æ—Å–µ–¥—è–º–∏ (siblings) ‚Äì –∏–º–µ—é—Ç –æ–±—â–µ–≥–æ –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—è.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ parent –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –∏ node1 != node2.
        """
        if node1 is None or node2 is None:
            return False
        parent1 = node1.parent if hasattr(node1, "parent") else None
        parent2 = node2.parent if hasattr(node2, "parent") else None
        return parent1 is not None and parent2 is not None and parent1 == parent2

    for parse_frag in parse_frags:
        print("\n=== –§—Ä–∞–≥–º–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ ===")
        print(parse_frag)
        print("=" * 50)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–æ—Ä—Ç–µ–∂–∞ (—Å—Ç–∞—Ä–∞—è vs –Ω–æ–≤–∞—è)
        if len(parse_frag) == 5:
            url, label_text, value_text, fragments, resource = parse_frag
        else:
            # —Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è (4 —ç–ª–µ–º–µ–Ω—Ç–∞)
            url, label_text, value_text, fragments = parse_frag
            resource = None

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ñ—Ä–∞–≥–º–µ–Ω—Ç
        if not fragments:
            print(
                f"[WARN] –ü—Ä–æ–ø—É—Å–∫ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞: label='{label_text}', value='{value_text}' - —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
            )
            continue

        soup = BeautifulSoup(fragments[0], "lxml")  # html —Ñ—Ä–∞–≥–º–µ–Ω—Ç

        # –ù–∞—Ö–æ–¥–∏–º —É–∑–ª—ã label –∏ value
        if search_mode == "text":
            label_nodes = find_text_nodes(
                soup, label_text, exact=exact_label, case_sensitive=case_sensitive
            )
            value_nodes = find_text_nodes(
                soup, value_text, exact=exact_value, case_sensitive=case_sensitive
            )
        else:
            label_nodes = find_elements_by_text(
                soup, label_text, exact=exact_label, case_sensitive=case_sensitive
            )
            value_nodes = find_elements_by_text(
                soup, value_text, exact=exact_value, case_sensitive=case_sensitive
            )

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç–æ–≥–æ label
        if label_text == "":
            # label –Ω–µ –∑–∞–¥–∞–Ω, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º label_nodes
            label_node = None
            if not value_nodes:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ value –≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ")
            value_node = get_deepest_node(value_nodes)
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç –∑–Ω–∞—á–µ–Ω–∏—è (—Ç–µ–≥)
            value_element = (
                value_node if isinstance(value_node, Tag) else value_node.parent
            )
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º value_element –≤ –∫–∞—á–µ—Å—Ç–≤–µ ancestor (–±–ª–∏–∂–∞–π—à–∏–π —Ç–µ–≥)
            ancestor = value_element
            # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–¥–Ω—è—Ç—å—Å—è –∫ —Ä–æ–¥–∏—Ç–µ–ª—é, –µ—Å–ª–∏ —Ç–µ–∫—É—â–∏–π ancestor –Ω–µ –∏–º–µ–µ—Ç –æ—Ç–ª–∏—á–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            while ancestor is not None and isinstance(ancestor, Tag):
                has_id = ancestor.has_attr("id")
                has_class = ancestor.has_attr("class")
                if has_id or has_class:
                    break
                parent = ancestor.parent
                if (
                    parent is None
                    or not isinstance(parent, Tag)
                    or parent.name in ("body", "html", "[document]")
                ):
                    break
                ancestor = parent
            # –ï—Å–ª–∏ ancestor –≤—Å—ë –µ—â—ë —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏–π, –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –ø—Ä–µ–¥–∫–∞
            while (
                ancestor is not None
                and isinstance(ancestor, Tag)
                and ancestor.name in ("body", "html", "[document]")
            ):
                if ancestor.parent is not None:
                    ancestor = ancestor.parent
                else:
                    break
        else:
            if not label_nodes or not value_nodes:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ label –∏–ª–∏ value –≤–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ")
            label_node = get_deepest_node(label_nodes)
            value_node = get_deepest_node(value_nodes)
            ancestor = lowest_common_ancestor(label_node, value_node)

        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if args.verbose:
            print(
                f"[DEBUG generate_pattern] label_text={label_text!r}, value_text={value_text!r}"
            )
            print(
                f"[DEBUG generate_pattern] value_node type={type(value_node)}, value_node={value_node}"
            )
            print(
                f"[DEBUG generate_pattern] ancestor type={type(ancestor)}, ancestor={ancestor}"
            )
            if hasattr(value_node, "name"):
                print(f"[DEBUG generate_pattern] value_node.name={value_node.name}")
            if isinstance(ancestor, Tag):
                print(f"[DEBUG generate_pattern] ancestor.name={ancestor.name}")

        if ancestor is None:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –æ–±—â–µ–≥–æ –ø—Ä–µ–¥–∫–∞ –¥–ª—è label –∏ value")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ç—Ä–∏–±—É—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        attribute = "text"
        if isinstance(value_node, Tag):
            if value_node.name == "a":
                # –î–ª—è –ø—É—Å—Ç–æ–≥–æ label –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–µ–µ —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∏—Å–∫–æ–º—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
                if label_text == "" and value_node.get_text(strip=True) == value_text:
                    attribute = "text"
                else:
                    attribute = "href"
            elif value_node.has_attr("src"):
                attribute = "src"
            elif value_node.has_attr("content"):
                attribute = "content"

        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ—Å—Ç—Ä–æ–∏—Ç—å CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∫–ª–∞—Å—Å—É –∏–ª–∏ id
        def get_css_selector(element: Tag) -> str:
            # –ï—Å–ª–∏ –µ—Å—Ç—å id ‚Äì –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            if element.has_attr("id"):
                return f"#{element['id']}"
            # –ï—Å–ª–∏ –µ—Å—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞)
            if element.has_attr("class"):
                classes = element["class"]
                if isinstance(classes, str):
                    classes = classes.split()
                if isinstance(classes, list):
                    for cls in classes:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ—Ç –∫–ª–∞—Å—Å –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ —É –¥–∞–Ω–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ soup
                        if len(soup.select(f".{cls}")) == 1:
                            return f".{cls}"
            # –ò–Ω–∞—á–µ —Å–µ–ª–µ–∫—Ç–æ—Ä –ø–æ —Ç–µ–≥—É —Å —É—á—ë—Ç–æ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (—É–ø—Ä–æ—â—ë–Ω–Ω–æ)
            # –ü–æ–∫–∞ –≤–µ—Ä–Ω—ë–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, —á—Ç–æ–±—ã –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ XPath
            return ""

        css_selector = ""
        if isinstance(value_node, Tag):
            css_selector = get_css_selector(value_node)

        if css_selector:
            # –ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ —Å–µ–ª–µ–∫—Ç–æ—Ä —É–Ω–∏–∫–∞–ª—å–Ω–æ –≤—ã–±–∏—Ä–∞–µ—Ç value –≤–Ω—É—Ç—Ä–∏ ancestor
            # (–ø—Ä–æ–ø—É—Å—Ç–∏–º —Å–ª–æ–∂–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É)
            pattern = {
                "type": "css",
                "selector": css_selector,
                "attribute": attribute,
                "label_text": label_text,
                "value_text": value_text,
                "clean_regex": None,
                "resource_id": resource.get("id") if resource else None,
            }
        else:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º XPath —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–ª–∞—Å—Å–æ–≤ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç –∑–Ω–∞—á–µ–Ω–∏—è (—Ç–µ–≥)
            value_element = (
                value_node if isinstance(value_node, Tag) else value_node.parent
            )
            # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Å –∑–Ω–∞—á–µ–Ω–∏—è (–≤–∫–ª—é—á–∞—è —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ –∫–ª–∞—Å—Å—ã)
            selected_class = collect_unique_classes(value_element, ancestor)

            # –°–æ–±–∏—Ä–∞–µ–º –∫–ª–∞—Å—Å—ã –ø—Ä–µ–¥–∫–∞
            ancestor_classes = []
            if ancestor.has_attr("class"):
                classes = ancestor["class"]
                if isinstance(classes, str):
                    classes = classes.split()
                if isinstance(classes, list):
                    ancestor_classes = classes

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–≥ –∑–Ω–∞—á–µ–Ω–∏—è
            value_tag = value_element.name if isinstance(value_element, Tag) else "*"

            if selected_class:
                # XPath –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∫–ª–∞—Å—Å—É –∑–Ω–∞—á–µ–Ω–∏—è
                xpath = f"//*[contains(@class, '{selected_class}')]"
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å sibling –æ—Ç–Ω–æ—à–µ–Ω–∏–µ, –µ—Å–ª–∏ label –∑–∞–¥–∞–Ω –∏ —É–∑–ª—ã —è–≤–ª—è—é—Ç—Å—è —Å–æ—Å–µ–¥—è–º–∏
                if (
                    label_text
                    and label_node is not None
                    and are_siblings(label_node, value_node)
                ):
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–≥ label
                    label_tag = label_node.name if isinstance(label_node, Tag) else "*"
                    ancestor_class_part = ""
                    if ancestor_classes:
                        ancestor_class_part = (
                            f"[contains(@class, '{ancestor_classes[0]}')]"
                        )
                    # XPath: ancestor —Å –∫–ª–∞—Å—Å–æ–º, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π label —Å —Ç–µ–∫—Å—Ç–æ–º, –∑–∞—Ç–µ–º —Å–ª–µ–¥—É—é—â–∏–π sibling –∑–Ω–∞—á–µ–Ω–∏—è
                    label_condition = build_xpath_text_condition(
                        label_text, exact=exact_label, case_sensitive=case_sensitive
                    )
                    xpath = f"//*{ancestor_class_part}[.//{label_tag}[{label_condition}]]//{label_tag}[{label_condition}]/following-sibling::{value_tag}"
                else:
                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π fallback —Å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º label (–µ—Å–ª–∏ label –∑–∞–¥–∞–Ω)
                    ancestor_class_part = ""
                    if ancestor_classes:
                        ancestor_class_part = (
                            f"[contains(@class, '{ancestor_classes[0]}')]"
                        )
                    if label_text:
                        # –ò—Å–∫–ª—é—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π —Ç–µ–∫—Å—Ç label
                        label_condition = build_xpath_text_condition(
                            label_text, exact=exact_label, case_sensitive=case_sensitive
                        )
                        xpath = f"//*{ancestor_class_part}[.//*[{label_condition}]]//{value_tag}[not({label_condition})]"
                    else:
                        xpath = f"//*{ancestor_class_part}//{value_tag}"

            pattern = {
                "type": "xpath",
                "selector": xpath,
                "attribute": attribute,
                "label_text": label_text,
                "value_text": value_text,
                "clean_regex": None,
                "resource_id": resource.get("id") if resource else None,
            }

        print(
            f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –ø–∞—Ç—Ç–µ—Ä–Ω: {pattern['type']} -> {pattern['selector']} (–∞—Ç—Ä–∏–±—É—Ç: {pattern['attribute']})"
        )

        patterns.append(pattern)

    return patterns


def extract_value(
    html_or_driver: Union[str, WebDriver],
    pattern: Dict[str, Any],
    use_selenium: Optional[bool] = None,
) -> Optional[str]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª—è –∏–∑ HTML –∏–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã Selenium –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–º—É –ø–∞—Ç—Ç–µ—Ä–Ω—É.
    """
    from selenium.webdriver.common.by import By

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, —Ä–∞–±–æ—Ç–∞–µ–º –ª–∏ —Å Selenium
    is_selenium = (
        use_selenium
        if use_selenium is not None
        else isinstance(html_or_driver, WebDriver)
    )

    if is_selenium:
        driver = html_or_driver
        selector = pattern["selector"]
        selector_type = pattern["type"]

        try:
            if selector_type == "css":
                element = driver.find_element(By.CSS_SELECTOR, selector)
            elif selector_type == "xpath":
                element = driver.find_element(By.XPATH, selector)
            else:
                raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Å–µ–ª–µ–∫—Ç–æ—Ä–∞: {selector_type}")
        except Exception:
            # –≠–ª–µ–º–µ–Ω—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω
            return None
    else:
        html = html_or_driver
        soup = BeautifulSoup(html, "lxml")
        selector = pattern["selector"]
        selector_type = pattern["type"]

        if selector_type == "css":
            element = soup.select_one(selector)
            if element is None:
                return None
        elif selector_type == "xpath":
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º lxml –¥–ª—è XPath
            from lxml import etree

            tree = etree.HTML(html)
            try:
                elements = tree.xpath(selector)
                if not elements:
                    return None
                element = elements[0]
                # –≠–ª–µ–º–µ–Ω—Ç lxml.etree._Element, –∏–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∞—Ç—Ä–∏–±—É—Ç–∞
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –Ω–∏–∂–µ –≤ –æ–±—â–µ–º –±–ª–æ–∫–µ –∫–æ–¥–∞
                pass  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, element —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç lxml —ç–ª–µ–º–µ–Ω—Ç
            except Exception:
                return None
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Å–µ–ª–µ–∫—Ç–æ—Ä–∞: {selector_type}")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∞—Ç—Ä–∏–±—É—Ç–∞
    attribute = pattern.get("attribute", "text")

    if is_selenium:
        if attribute == "text":
            value = element.text
        else:
            value = element.get_attribute(attribute)
    else:
        # BeautifulSoup –∏–ª–∏ lxml —ç–ª–µ–º–µ–Ω—Ç
        if selector_type == "css":
            if attribute == "text":
                value = element.get_text(strip=True)
            else:
                value = element.get(attribute)
        else:  # xpath —Å lxml
            if attribute == "text":
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º XPath string() –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ —ç–ª–µ–º–µ–Ω—Ç–∞ –∏ –µ–≥–æ –ø–æ—Ç–æ–º–∫–æ–≤
                text = element.xpath("string()")
                value = text if isinstance(text, str) else (text[0] if text else "")
            else:
                value = element.get(attribute)

    if value is None:
        return None

    # –ü—Ä–∏–º–µ–Ω—è–µ–º clean_regex, –µ—Å–ª–∏ –µ—Å—Ç—å
    clean_regex = pattern.get("clean_regex")
    if clean_regex and value:
        import re

        match = re.search(clean_regex, value)
        if match:
            value = match.group(1) if match.groups() else match.group(0)

    return value.strip() if isinstance(value, str) else str(value)


def print_fragments(fragments: list[tuple]) -> None:
    """–í—ã–≤–æ–¥–∏—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –≤ –∫–æ–Ω—Å–æ–ª—å."""
    if not fragments:
        print("‚ùå –§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        return
    print(f"–ù–∞–π–¥–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(fragments)}")
    for i, frag in enumerate(fragments, 1):
        print(f"\n=== –§—Ä–∞–≥–º–µ–Ω—Ç {i} ===")
        print(f"URL: {frag[0]}, Label: '{frag[1]}', Value: '{frag[2]}'")
        print("-" * 50)
        print(frag[3])
        print("=" * 50)


def run_parse(args: argparse.Namespace, driver=None) -> Union[bool, list[str]]:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ñ—Ä–∞–≥–º–µ–Ω—Ç –Ω–∞–π–¥–µ–Ω, –∏–Ω–∞—á–µ False.
    """
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ–∏—Å–∫–∞
    if args.test:
        search_data = get_test_data_to_parse()
    else:
        search_data = {args.url: [{"label": args.label, "value": args.value}]}

    all_fragments = []
    driver_created = False
    if driver is None and args.selenium:
        driver = create_driver(headless=False)
        driver_created = True
    try:
        for url, pairs in search_data.items():
            if args.verbose:
                print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ URL: {url}")

            if driver:
                driver.get(url)
                wait_for_page_with_protection(driver)

            for pair in pairs:
                if args.verbose:
                    print(
                        f"\n=== –ü–æ–∏—Å–∫ –ø–∞—Ä—ã: '{pair['label']}' ‚Äì '{pair['value']}' ==="
                    )

                fragments = search_web(
                    url,
                    is_driver=args.selenium,
                    label=pair["label"],
                    value=pair["value"],
                    exact_label=args.exact,
                    exact_value=args.exact,
                    case_sensitive=args.case_sensitive,
                    all_matches=args.all_matches,
                    verbose=args.verbose,
                    search_mode=args.search_mode,
                    driver=driver,
                )
                config = ScraperConfig()
                resource = get_resource_by_url(url, config)
                if fragments:
                    all_fragments.extend(
                        [(url, pair["label"], pair["value"], fragments, resource)]
                    )
                else:
                    if args.verbose:
                        print(
                            f"[WARN] –î–ª—è –ø–∞—Ä—ã '{pair['label']}' - '{pair['value']}' —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã"
                        )
    finally:
        if driver_created and driver:
            driver.quit()

    if not all_fragments:
        print("‚ùå –§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
        if not args.verbose:
            print(
                "üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º --verbose, —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."
            )
        return False

    print_fragments(all_fragments)  # html —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è –ø–µ—Ä–≤–æ–π –ø–∞—Ä—ã (–¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏)
    return all_fragments


def run_search(args, patterns, driver=None) -> list[Optional[str]]:
    search_data = get_test_data_to_search()
    all_extracted = []

    # –°–æ–∑–¥–∞—ë–º –¥—Ä–∞–π–≤–µ—Ä –æ–¥–∏–Ω —Ä–∞–∑, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Selenium
    driver_created = False
    if driver is None and args.selenium:
        driver = create_driver(headless=False)
        driver_created = True

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ resource_id –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
    patterns_by_resource = {}
    patterns_without_resource = []
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞—ë–º –º–∞–ø–ø–∏–Ω–≥ –ø–æ –∫–ª—é—á–∞–º (resource_id, label, value) –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
    patterns_by_key = {}

    for pat in patterns:
        resource_id = pat.get("resource_id")
        label_text = pat.get("label_text", "")
        value_text = pat.get("value_text", "")

        if resource_id:
            patterns_by_resource.setdefault(resource_id, []).append(pat)
            # –°–æ–∑–¥–∞—ë–º –∫–ª—é—á –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
            key = (resource_id, label_text, value_text)
            patterns_by_key[key] = pat
        else:
            patterns_without_resource.append(pat)
            # –î–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –±–µ–∑ resource_id –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ label/value
            key = (None, label_text, value_text)
            patterns_by_key[key] = pat

    def find_best_pattern(resource_id, label, value, available_patterns):
        """
        –ù–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–ª—É—á—à–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–π –ø–∞—Ä—ã (label, value) –∏ resource_id.

        –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –ø–æ–∏—Å–∫–∞:
        1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ (resource_id, label, value)
        2. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ (resource_id, label) (value –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è)
        3. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ (resource_id) (—Ç–æ–ª—å–∫–æ resource_id)
        4. –õ—é–±–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω –±–µ–∑ resource_id —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º label/value
        5. –ü–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
        """
        # 1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        exact_key = (resource_id, label, value)
        if exact_key in patterns_by_key:
            return patterns_by_key[exact_key]

        # 2. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ resource_id –∏ label (value –ª—é–±–æ–µ)
        if resource_id:
            for key, pat in patterns_by_key.items():
                if key[0] == resource_id and key[1] == label:
                    return pat

        # 3. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø–æ resource_id
        if resource_id and resource_id in patterns_by_resource:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —ç—Ç–æ–≥–æ —Ä–µ—Å—É—Ä—Å–∞
            return patterns_by_resource[resource_id][0]

        # 4. –ü–∞—Ç—Ç–µ—Ä–Ω—ã –±–µ–∑ resource_id —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º label/value
        for pat in patterns_without_resource:
            if pat.get("label_text") == label and pat.get("value_text") == value:
                return pat

        # 5. –ü–µ—Ä–≤—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
        if available_patterns:
            return available_patterns[0]

        return None

    # –ö–æ–Ω—Ñ–∏–≥ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ—Å—É—Ä—Å–∞ –ø–æ URL
    config = ScraperConfig()

    try:
        for url, pairs in search_data.items():
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ—Å—É—Ä—Å –ø–æ URL
            resource = get_resource_by_url(url, config)
            resource_id = resource.get("id") if resource else None

            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ä–µ—Å—É—Ä—Å–∞
            resource_patterns = []
            if resource_id and resource_id in patterns_by_resource:
                resource_patterns = patterns_by_resource[resource_id]
            elif patterns_without_resource:
                resource_patterns = patterns_without_resource
            elif patterns:
                resource_patterns = patterns
            else:
                print("[ERROR] –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")

            print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ URL: {url} (—Ä–µ—Å—É—Ä—Å: {resource_id})")
            print(f"   –î–æ—Å—Ç—É–ø–Ω–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –¥–ª—è —Ä–µ—Å—É—Ä—Å–∞: {len(resource_patterns)}")

            if driver:
                driver.get(url)
                wait_for_page_with_protection(driver)

            for idx, pair in enumerate(pairs):
                print(f"\n=== –ü–æ–∏—Å–∫ –ø–∞—Ä—ã: '{pair['label']}' ‚Äì '{pair['value']}' ===")

                # –í—ã–±–∏—Ä–∞–µ–º –Ω–∞–∏–ª—É—á—à–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Ç–µ–∫—É—â–µ–π –ø–∞—Ä—ã
                pattern = find_best_pattern(
                    resource_id, pair["label"], pair["value"], resource_patterns
                )

                if pattern:
                    print(
                        f"[DEBUG] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–∞—Ç—Ç–µ—Ä–Ω: {pattern['type']} -> {pattern['selector']}"
                    )
                    print(
                        f"[DEBUG] –ü–∞—Ç—Ç–µ—Ä–Ω —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç: label='{pattern.get('label_text')}', value='{pattern.get('value_text')}'"
                    )
                else:
                    print("[WARN] –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è")

                search_frags = search_web(
                    url=url,
                    is_driver=args.selenium,
                    label=pair["label"],
                    value=pair["value"],
                    exact_label=args.exact,
                    exact_value=args.exact,
                    case_sensitive=args.case_sensitive,
                    all_matches=args.all_matches,
                    verbose=args.verbose,
                    search_mode=args.search_mode,
                    driver=driver,
                )

                if not search_frags:
                    print("[WARN] –§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∑–Ω–∞—á–µ–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å
                    if pattern:
                        if driver is not None:
                            extracted = extract_value(driver, pattern)
                        else:
                            # –ó–∞–≥—Ä—É–∂–∞–µ–º HTML —á–µ—Ä–µ–∑ requests
                            import requests
                            from requests.exceptions import RequestException

                            try:
                                resp = requests.get(
                                    url,
                                    headers={"User-Agent": "Mozilla/5.0"},
                                    timeout=10,
                                )
                                resp.raise_for_status()
                                extracted = extract_value(resp.text, pattern)
                            except RequestException as e:
                                print(f"[ERROR] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É: {e}")
                                extracted = None
                    else:
                        extracted = None
                elif pattern:
                    extracted = extract_value(search_frags[0], pattern)
                else:
                    extracted = None
                    print("[ERROR] –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–±—Ä–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è")

                print(f"–ò–∑–≤–ª–µ—á—ë–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {extracted}")

                all_extracted.append(extracted)
    finally:
        if driver_created and driver is not None:
            driver.quit()

    return all_extracted


def main() -> None:
    default_arg_values = {
        "url": r"https://book.ru/book/943665",
        "label": "–ì–æ–¥ –∏–∑–¥–∞–Ω–∏—è:",
        "value": "2022",
        "selenium": False,
        "exact": True,
        "verbose": False,
        "test": True,
        "search_mode": "element",
        "all_matches": True,
    }
    args = parse_arguments(**default_arg_values)

    driver = None
    if args.selenium:
        driver = create_driver(headless=False)

    try:
        parse_frags = run_parse(args, driver=driver)
        if not parse_frags:
            print("   ‚ùå –§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
            sys.exit(1)

        patterns = generate_pattern(parse_frags, args=args)

        run_search(args, patterns, driver=driver)
    finally:
        if driver is not None:
            driver.quit()


if __name__ == "__main__":
    main()
