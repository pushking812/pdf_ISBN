#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã:
1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ISBN –∏–∑ PDF —Ñ–∞–π–ª–æ–≤
2. –ü–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ API –∫–ª–∏–µ–Ω—Ç–æ–≤ (Google Books, Open Library, –†–ì–ë)
3. –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö —Å –≤–µ–±-—Å–∞–π—Ç–æ–≤ (–ß–∏—Ç–∞–π-–≥–æ—Ä–æ–¥, Book.ru, RSL)
4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à
6. –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

import asyncio
import json
import logging
import sys
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
import pandas as pd
from tabulate import tabulate

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∫–æ—Ä–Ω—é –ø—Ä–æ–µ–∫—Ç–∞
sys.path.insert(0, str(Path(__file__).parent.parent))

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class BookData:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –æ –∫–Ω–∏–≥–µ."""
    isbn: str
    title: Optional[str] = None
    authors: List[str] = None
    publisher: Optional[str] = None
    year: Optional[str] = None
    pages: Optional[int] = None
    price: Optional[str] = None
    sources: List[str] = None
    extracted_from: Optional[str] = None
    
    def __post_init__(self):
        if self.authors is None:
            self.authors = []
        if self.sources is None:
            self.sources = []
    
    def to_dict(self) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ —Å–ª–æ–≤–∞—Ä—å."""
        return asdict(self)
    
    def merge(self, other: 'BookData'):
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥—Ä—É–≥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞."""
        if not self.title and other.title:
            self.title = other.title
        if not self.authors and other.authors:
            self.authors = other.authors
        if not self.publisher and other.publisher:
            self.publisher = other.publisher
        if not self.year and other.year:
            self.year = other.year
        if not self.pages and other.pages:
            self.pages = other.pages
        if not self.price and other.price:
            self.price = other.price
        if other.sources:
            self.sources.extend(other.sources)
        if other.extracted_from:
            self.extracted_from = other.extracted_from


class FullPipeline:
    """–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–Ω–∏–≥."""
    
    def __init__(self, use_new_architecture: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞.
        
        Args:
            use_new_architecture: –ï—Å–ª–∏ True, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥–∞.
                                  –ï—Å–ª–∏ False, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å –≤–∫–ª–∞–¥–∫–∞–º–∏.
        """
        self.books_data: Dict[str, BookData] = {}
        self.use_new_architecture = use_new_architecture
        self.new_architecture_used = False  # –§–ª–∞–≥, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
    
    async def extract_isbns_from_pdfs(self, books_dir: str = "_books", limit: int = 3) -> List[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç ISBN –∏–∑ PDF —Ñ–∞–π–ª–æ–≤.
        
        Args:
            books_dir: –ü–∞–ø–∫–∞ —Å PDF —Ñ–∞–π–ª–∞–º–∏
            limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö ISBN
        """
        logger.info(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ISBN –∏–∑ PDF —Ñ–∞–π–ª–æ–≤ –≤ {books_dir}...")
        
        try:
            from pdf_extract_isbn import scan_pdfs
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ PDF —Ñ–∞–π–ª–æ–≤
            pdf_files = list(Path(books_dir).glob("*.pdf"))
            if not pdf_files:
                logger.warning(f"PDF —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {books_dir}")
                return []
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            pdf_files = pdf_files[:limit]
            
            isbns = []
            for pdf_file in pdf_files:
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º ISBN –∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                    from pdf_extract_isbn import extract_isbn_from_pdf
                    
                    isbn, source = extract_isbn_from_pdf(
                        str(pdf_file),
                        strict=False,  # loose=True —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–Ω–æ strict=False
                        include_metadata=True,
                        max_pages=5
                    )
                    
                    if isbn:
                        isbns.append(isbn)
                        logger.info(f"  üìñ {pdf_file.name} -> ISBN: {isbn} (–∏—Å—Ç–æ—á–Ω–∏–∫: {source})")
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∏—Å—Ç–æ—á–Ω–∏–∫–µ
                        book_data = BookData(
                            isbn=isbn,
                            extracted_from=pdf_file.name
                        )
                        self.books_data[isbn] = book_data
                        
                except Exception as e:
                    logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {pdf_file.name}: {e}")
            
            logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(isbns)} ISBN –∏–∑ {len(pdf_files)} PDF —Ñ–∞–π–ª–æ–≤")
            return isbns
            
        except ImportError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å pdf_extract_isbn: {e}")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ ISBN
            return self._get_test_isbns(limit)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ ISBN: {e}")
            return self._get_test_isbns(limit)
    
    def _get_test_isbns(self, limit: int = 3) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ ISBN."""
        test_isbns = [
            "9781835081167",  # Hands-On Python for DevOps
            "9780134173276",  # Python Distilled
            "9785977520966",  # –ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –±–µ–∫–µ–Ω–¥–∞ –Ω–∞ Python
            "9781805125105",  # Security Automation with Python
            "9798868808814",  # Generative AI Apps with LangChain
        ]
        
        isbns = test_isbns[:limit]
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–µ—Å—Ç–æ–≤—ã–µ ISBN: {isbns}")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö ISBN
        for isbn in isbns:
            self.books_data[isbn] = BookData(isbn=isbn, extracted_from="test_data")
        
        return isbns
    
    async def search_via_api_clients(self, isbns: List[str]):
        """
        –ü–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ API –∫–ª–∏–µ–Ω—Ç–æ–≤.
        
        Args:
            isbns: –°–ø–∏—Å–æ–∫ ISBN –¥–ª—è –ø–æ–∏—Å–∫–∞
        """
        logger.info(f"üåê –ü–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ API –∫–ª–∏–µ–Ω—Ç–æ–≤ –¥–ª—è {len(isbns)} ISBN...")
        
        for isbn in isbns:
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Google Books API
                from api_clients import GoogleBooksClient
                
                client = GoogleBooksClient()
                result = await client.search_by_isbn(isbn)
                
                if result:
                    book_data = BookData(
                        isbn=isbn,
                        title=result.get("title"),
                        authors=result.get("authors", []),
                        publisher=result.get("publisher"),
                        year=result.get("published_date"),
                        pages=result.get("page_count"),
                        sources=["Google Books API"]
                    )
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                    if isbn in self.books_data:
                        self.books_data[isbn].merge(book_data)
                    else:
                        self.books_data[isbn] = book_data
                    
                    logger.info(f"  ‚úÖ {isbn}: –Ω–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ Google Books API")
                else:
                    logger.info(f"  ‚ö†Ô∏è  {isbn}: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ Google Books API")
                    
            except ImportError:
                logger.warning("  üìù –ú–æ–¥—É–ª—å api_clients –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º API –ø–æ–∏—Å–∫")
                break
            except Exception as e:
                logger.error(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —á–µ—Ä–µ–∑ API –¥–ª—è {isbn}: {e}")
    
    async def scrape_via_web_parsers(self, isbns: List[str]):
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö —Å –≤–µ–±-—Å–∞–π—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–∫–ª–∞–¥–æ–∫ –±—Ä–∞—É–∑–µ—Ä–∞.
        
        Args:
            isbns: –°–ø–∏—Å–æ–∫ ISBN –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
        """
        logger.info(f"üï∏Ô∏è  –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö —Å –≤–µ–±-—Å–∞–π—Ç–æ–≤ –¥–ª—è {len(isbns)} ISBN...")
        
        # –ï—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ñ–ª–∞–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë
        if self.use_new_architecture:
            logger.info("  –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö)...")
            await self.use_new_architecture(isbns)
            self.new_architecture_used = True
            return
        
        try:
            # –ü—Ä—è–º–æ–π –∏–º–ø–æ—Ä—Ç —Å—Ç–∞—Ä–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤–∫–ª–∞–¥–æ–∫
            import sys
            sys.path.insert(0, '.')
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞–ø—Ä—è–º—É—é –∏–∑ main.py, –∫–æ—Ç–æ—Ä—ã–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ç–∞—Ä—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
            from main import parallel_search_with_progress
            
            logger.info(f"  –ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥–∞ —Å –≤–∫–ª–∞–¥–∫–∞–º–∏ (—Å—Ç–∞—Ä–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)...")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            import asyncio
            from config import ScraperConfig
            
            config = ScraperConfig()
            config.headless = True
            config.max_tabs = min(3, len(isbns))
            config.wait_product_link = 5
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∞–ø–∏–Ω–≥ —á–µ—Ä–µ–∑ —Å—Ç–∞—Ä—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
            results = await parallel_search_with_progress(isbns, config)
            
            success_count = 0
            for isbn, result in zip(isbns, results):
                if result and result.get("title"):
                    book_data = BookData(
                        isbn=isbn,
                        title=result.get("title"),
                        authors=result.get("authors", []),
                        price=result.get("price"),
                        sources=[result.get("source", "web_scraper")]
                    )
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                    if isbn in self.books_data:
                        self.books_data[isbn].merge(book_data)
                    else:
                        self.books_data[isbn] = book_data
                    
                    logger.info(f"  ‚úÖ {isbn}: –Ω–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥")
                    success_count += 1
                else:
                    logger.info(f"  ‚ö†Ô∏è  {isbn}: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥")
            
            logger.info(f"  –°—Ç–∞—Ä–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: –Ω–∞–π–¥–µ–Ω–æ {success_count} –∏–∑ {len(isbns)} –∫–Ω–∏–≥")
            
            # –ï—Å–ª–∏ —Å—Ç–∞—Ä–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞—à–ª–∞ –Ω–∏ –æ–¥–Ω–æ–π –∫–Ω–∏–≥–∏, –ø—Ä–æ–±—É–µ–º –Ω–æ–≤—É—é –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
            if success_count == 0:
                logger.info("  –°—Ç–∞—Ä–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ –Ω–∞—à–ª–∞ –¥–∞–Ω–Ω—ã–µ, –ø—Ä–æ–±—É–µ–º –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É...")
                await self.use_new_architecture(isbns)
                self.new_architecture_used = True
                    
        except ImportError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å main: {e}")
            logger.info("  –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç...")
            await self.use_new_architecture(isbns)
            self.new_architecture_used = True
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥–µ: {e}")
            logger.info("  –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç...")
            await self.use_new_architecture(isbns)
            self.new_architecture_used = True
    
    async def use_new_architecture(self, isbns: List[str]):
        """
        –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–∞–Ω–Ω—ã—Ö.
        
        Args:
            isbns: –°–ø–∏—Å–æ–∫ ISBN –¥–ª—è –ø–æ–∏—Å–∫–∞
        """
        logger.info(f"üöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è {len(isbns)} ISBN...")
        
        try:
            from scraper_core.orchestrator.legacy_adapter import LegacyScraperAdapter
            
            adapter = LegacyScraperAdapter()
            results = await adapter.async_parallel_search(isbns)
            
            for isbn, result in zip(isbns, results):
                if result:
                    book_data = BookData(
                        isbn=isbn,
                        title=result.get("title"),
                        authors=result.get("authors", []),
                        price=result.get("price"),
                        sources=[f"new_arch_{result.get('source', 'unknown')}"]
                    )
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                    if isbn in self.books_data:
                        self.books_data[isbn].merge(book_data)
                    else:
                        self.books_data[isbn] = book_data
                    
                    logger.info(f"  ‚úÖ {isbn}: –Ω–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É")
                else:
                    logger.info(f"  ‚ö†Ô∏è  {isbn}: –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —á–µ—Ä–µ–∑ –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É")
                    
        except ImportError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É: {e}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ: {e}")
    
    def save_to_cache(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à."""
        logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –∫—ç—à...")
        
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ isbn_data_cache.json
            cache_data = {
                "version": 1,
                "entries": {}
            }
            
            for isbn, book_data in self.books_data.items():
                cache_data["entries"][isbn] = book_data.to_dict()
            
            with open("isbn_data_cache.json", "w", encoding="utf-8") as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ {len(self.books_data)} –∫–Ω–∏–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ isbn_data_cache.json")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –∫—ç—à: {e}")
    
    def display_results(self):
        """–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
        logger.info("üìä –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        if not self.books_data:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            return
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü—É
        table_data = []
        for isbn, book_data in self.books_data.items():
            table_data.append({
                "ISBN": isbn,
                "–ù–∞–∑–≤–∞–Ω–∏–µ": book_data.title or "–ù–µ –Ω–∞–π–¥–µ–Ω–æ",
                "–ê–≤—Ç–æ—Ä—ã": ", ".join(book_data.authors) if book_data.authors else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ",
                "–ì–æ–¥": book_data.year or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ",
                "–¶–µ–Ω–∞": book_data.price or "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ",
                "–ò—Å—Ç–æ—á–Ω–∏–∫–∏": ", ".join(book_data.sources) if book_data.sources else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
            })
        
        # –í—ã–≤–æ–¥–∏–º —Ç–∞–±–ª–∏—Ü—É
        print("\n" + "=" * 120)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–õ–ù–û–ì–û –ü–ê–ô–ü–õ–ê–ô–ù–ê –û–ë–†–ê–ë–û–¢–ö–ò –ö–ù–ò–ì")
        print("=" * 120)
        
        df = pd.DataFrame(table_data)
        print(tabulate(df, headers="keys", tablefmt="grid", showindex=False))
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\n" + "=" * 120)
        print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"  –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ ISBN: {len(self.books_data)}")
        
        found_books = sum(1 for b in self.books_data.values() if b.title)
        print(f"  –ù–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {found_books} ({found_books/len(self.books_data):.1%})")
        
        sources_count = {}
        for book_data in self.books_data.values():
            for source in book_data.sources:
                sources_count[source] = sources_count.get(source, 0) + 1
        
        if sources_count:
            print("  –ò—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö:")
            for source, count in sources_count.items():
                print(f"    - {source}: {count} –∫–Ω–∏–≥")
        
        print("=" * 120)
    
    async def run_full_pipeline(self, books_dir: str = "_books", limit: int = 3):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω.
        
        Args:
            books_dir: –ü–∞–ø–∫–∞ —Å PDF —Ñ–∞–π–ª–∞–º–∏
            limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ ISBN
        """
        logger.info("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ü–ê–ô–ü–õ–ê–ô–ù–ê –û–ë–†–ê–ë–û–¢–ö–ò –ö–ù–ò–ì")
        logger.info("=" * 60)
        
        start_time = time.time()
        
        # –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ISBN –∏–∑ PDF
        isbns = await self.extract_isbns_from_pdfs(books_dir, limit)
        
        if not isbns:
            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ISBN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        
        # –®–∞–≥ 2: –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ API –∫–ª–∏–µ–Ω—Ç–æ–≤
        await self.search_via_api_clients(isbns)
        
        # –®–∞–≥ 3: –ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–∏–±–æ —Å—Ç–∞—Ä—É—é, –ª–∏–±–æ –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É)
        await self.scrape_via_web_parsers(isbns)
        
        # –®–∞–≥ 4: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ –±—ã–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —Ä–∞–Ω–µ–µ
        # –∏ –µ—Å–ª–∏ –º—ã —Ö–æ—Ç–∏–º —Å—Ä–∞–≤–Ω–∏—Ç—å –æ–±–µ —Å–∏—Å—Ç–µ–º—ã (–¥–ª—è A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
        if not self.new_architecture_used and not self.use_new_architecture:
            logger.info("üî¨ –ó–∞–ø—É—Å–∫ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)...")
            await self.use_new_architecture(isbns)
        
        # –®–∞–≥ 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à
        self.save_to_cache()
        
        # –®–∞–≥ 6: –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.display_results()
        
        total_time = time.time() - start_time
        logger.info(f"‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {total_time:.2f} —Å–µ–∫—É–Ω–¥")


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–Ω–∏–≥"
    )
    
    parser.add_argument(
        "--books-dir",
        "-b",
        type=str,
        default="_books",
        help="–ü–∞–ø–∫–∞ —Å PDF —Ñ–∞–π–ª–∞–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: _books)"
    )
    
    parser.add_argument(
        "--limit",
        "-l",
        type=int,
        default=3,
        help="–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ ISBN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 3)"
    )
    
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥"
    )
    
    parser.add_argument(
        "--use-new-architecture",
        "-n",
        action="store_true",
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –≤–º–µ—Å—Ç–æ —Å—Ç–∞—Ä–æ–π –¥–ª—è –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥–∞"
    )
    
    parser.add_argument(
        "--compare-both",
        "-c",
        action="store_true",
        help="–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±–µ —Å–∏—Å—Ç–µ–º—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)"
    )
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω —Ñ–ª–∞–≥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é,
    # –Ω–æ —Ä–∞–∑—Ä–µ—à–∞–µ–º –∑–∞–ø—É—Å–∫ –Ω–æ–≤–æ–π –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    if args.compare_both:
        logger.info("üî¨ –†–µ–∂–∏–º A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: –±—É–¥—É—Ç –∑–∞–ø—É—â–µ–Ω—ã –æ–±–µ —Å–∏—Å—Ç–µ–º—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
        pipeline = FullPipeline(use_new_architecture=False)
        await pipeline.run_full_pipeline(args.books_dir, args.limit)
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
        pipeline = FullPipeline(use_new_architecture=args.use_new_architecture)
        await pipeline.run_full_pipeline(args.books_dir, args.limit)


if __name__ == "__main__":
    asyncio.run(main())