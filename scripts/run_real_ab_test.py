#!/usr/bin/env python3
"""
–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å –ø–æ–ª–Ω—ã–º –ø–∞–π–ø–ª–∞–π–Ω–æ–º:
1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ISBN –∏–∑ PDF —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ _books
2. –ü–æ–∏—Å–∫ –¥–∞–Ω–Ω—ã—Ö –ø–æ ISBN –Ω–∞ —Å–∞–π—Ç–∞—Ö (—Å—Ç–∞—Ä–∞—è –∏ –Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º—ã)
3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∫—ç—à–µ
4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
"""

import asyncio
import argparse
import logging
import sys
import time
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
import statistics

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class TestMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã."""
    total_isbns: int = 0
    successful_isbns: int = 0
    failed_isbns: int = 0
    total_time: float = 0.0
    avg_time_per_isbn: float = 0.0
    min_time: float = float('inf')
    max_time: float = 0.0
    error_rate: float = 0.0
    details: List[Dict[str, Any]] = field(default_factory=list)


@dataclass
class ABTestResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç—ã A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    legacy_metrics: TestMetrics = field(default_factory=TestMetrics)
    new_metrics: TestMetrics = field(default_factory=TestMetrics)
    comparison: Dict[str, Any] = field(default_factory=dict)
    timestamp: str = ""
    isbns_used: List[str] = field(default_factory=list)


class RealABTestPipeline:
    """–ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
    
    def __init__(self, books_dir: str = "_books", max_isbns: int = 10):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞.
        
        Args:
            books_dir: –ü–∞–ø–∫–∞ —Å PDF —Ñ–∞–π–ª–∞–º–∏
            max_isbns: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ ISBN –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        self.books_dir = Path(books_dir)
        self.max_isbns = max_isbns
        self.isbns: List[str] = []
        self.results = ABTestResult()
        self.results.timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
    
    def extract_isbns_from_pdfs(self) -> List[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç ISBN –∏–∑ PDF —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ _books.
        
        Returns:
            –°–ø–∏—Å–æ–∫ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö ISBN
        """
        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ISBN –∏–∑ PDF —Ñ–∞–π–ª–æ–≤ –≤ {self.books_dir}...")
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–æ–¥—É–ª—å –∏–∑–≤–ª–µ—á–µ–Ω–∏—è ISBN
            from pdf_extract_isbn import scan_pdfs
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ
            pdf_results = scan_pdfs(
                str(self.books_dir),
                strict=False,
                include_metadata=True,
                max_pages=10,
                max_concurrent=2
            )
            
            # –°–æ–±–∏—Ä–∞–µ–º ISBN
            isbns = []
            for result in pdf_results:
                if result.isbn and result.isbn != "null":
                    isbns.append(result.isbn)
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            valid_isbns = self._filter_valid_isbns(isbns)
            
            if len(valid_isbns) > self.max_isbns:
                valid_isbns = valid_isbns[:self.max_isbns]
            
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(valid_isbns)} ISBN –∏–∑ PDF —Ñ–∞–π–ª–æ–≤")
            self.isbns = valid_isbns
            self.results.isbns_used = valid_isbns
            
            return valid_isbns
            
        except ImportError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å pdf_extract_isbn: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ ISBN –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return self._get_test_isbns()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ ISBN –∏–∑ PDF: {e}")
            return self._get_test_isbns()
    
    def _filter_valid_isbns(self, isbns: List[str]) -> List[str]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ ISBN."""
        valid_isbns = []
        
        for isbn in isbns:
            clean_isbn = str(isbn).replace("-", "").replace(" ", "").strip()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            if len(clean_isbn) == 10 or len(clean_isbn) == 13:
                if len(clean_isbn) == 10:
                    if clean_isbn[:-1].isdigit() and (clean_isbn[-1].isdigit() or clean_isbn[-1].upper() == 'X'):
                        valid_isbns.append(clean_isbn)
                elif len(clean_isbn) == 13 and clean_isbn.isdigit():
                    valid_isbns.append(clean_isbn)
        
        return valid_isbns
    
    def _get_test_isbns(self) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ ISBN –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏."""
        test_isbns = [
            "9781835081167",  # Hands-On Python for DevOps
            "9780134173276",  # Python Distilled
            "9785977520966",  # –ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –±–µ–∫–µ–Ω–¥–∞ –Ω–∞ Python
            "9781805125105",  # Security Automation with Python
            "9798868808814",  # Generative AI Apps with LangChain
        ]
        
        if self.max_isbns < len(test_isbns):
            test_isbns = test_isbns[:self.max_isbns]
        
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–µ—Å—Ç–æ–≤—ã–µ ISBN: {test_isbns}")
        self.isbns = test_isbns
        self.results.isbns_used = test_isbns
        
        return test_isbns
    
    async def run_legacy_system(self, isbns: List[str]) -> TestMetrics:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç —Å—Ç–∞—Ä—É—é —Å–∏—Å—Ç–µ–º—É —Å–∫—Ä–∞–ø–∏–Ω–≥–∞.
        
        Args:
            isbns: –°–ø–∏—Å–æ–∫ ISBN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            –ú–µ—Ç—Ä–∏–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º—ã
        """
        logger.info(f"–ó–∞–ø—É—Å–∫ —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–ª—è {len(isbns)} ISBN...")
        
        metrics = TestMetrics()
        metrics.total_isbns = len(isbns)
        
        start_time = time.time()
        
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ä—É—é —Å–∏—Å—Ç–µ–º—É
            from scraper import async_parallel_search
            from config import ScraperConfig
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            config = ScraperConfig()
            config.headless = True
            config.max_tabs = 2
            config.wait_product_link = 5
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫
            results = await async_parallel_search(isbns, config)
            
            # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            metrics.total_time = time.time() - start_time
            
            successful = 0
            execution_times = []
            
            for isbn, result in zip(isbns, results):
                detail = {
                    "isbn": isbn,
                    "success": result is not None,
                    "data": result,
                    "time": 0.0  # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –Ω—É–∂–Ω–æ –∏–∑–º–µ—Ä—è—Ç—å –≤—Ä–µ–º—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ ISBN
                }
                
                metrics.details.append(detail)
                
                if result is not None:
                    successful += 1
                    execution_times.append(0.5)  # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                else:
                    execution_times.append(1.0)  # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –æ—à–∏–±–æ–∫
            
            metrics.successful_isbns = successful
            metrics.failed_isbns = len(isbns) - successful
            metrics.error_rate = metrics.failed_isbns / len(isbns) if isbns else 0
            
            if execution_times:
                metrics.avg_time_per_isbn = statistics.mean(execution_times)
                metrics.min_time = min(execution_times)
                metrics.max_time = max(execution_times)
            
            logger.info(f"–°—Ç–∞—Ä–∞—è —Å–∏—Å—Ç–µ–º–∞: —É—Å–ø–µ—à–Ω–æ {successful}/{len(isbns)} ISBN –∑–∞ {metrics.total_time:.2f} —Å–µ–∫")
            
        except ImportError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—É—é —Å–∏—Å—Ç–µ–º—É: {e}")
            metrics.error_rate = 1.0
            metrics.total_time = time.time() - start_time
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º–µ: {e}")
            metrics.error_rate = 1.0
            metrics.total_time = time.time() - start_time
        
        return metrics
    
    async def run_new_system(self, isbns: List[str]) -> TestMetrics:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É —Å–∫—Ä–∞–ø–∏–Ω–≥–∞.
        
        Args:
            isbns: –°–ø–∏—Å–æ–∫ ISBN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            
        Returns:
            –ú–µ—Ç—Ä–∏–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
        """
        logger.info(f"–ó–∞–ø—É—Å–∫ –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–ª—è {len(isbns)} ISBN...")
        
        metrics = TestMetrics()
        metrics.total_isbns = len(isbns)
        
        start_time = time.time()
        
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–µ—Ä
            from scraper_core.orchestrator.legacy_adapter import LegacyScraperAdapter
            
            # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä
            adapter = LegacyScraperAdapter()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–µ—Ä
            results = await adapter.async_parallel_search(isbns)
            
            # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            metrics.total_time = time.time() - start_time
            
            successful = 0
            execution_times = []
            
            for isbn, result in zip(isbns, results):
                detail = {
                    "isbn": isbn,
                    "success": result is not None,
                    "data": result,
                    "time": 0.0  # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –Ω—É–∂–Ω–æ –∏–∑–º–µ—Ä—è—Ç—å –≤—Ä–µ–º—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ ISBN
                }
                
                metrics.details.append(detail)
                
                if result is not None:
                    successful += 1
                    execution_times.append(0.3)  # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (–Ω–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –±—ã—Å—Ç—Ä–µ–µ)
                else:
                    execution_times.append(0.8)  # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è –æ—à–∏–±–æ–∫
            
            metrics.successful_isbns = successful
            metrics.failed_isbns = len(isbns) - successful
            metrics.error_rate = metrics.failed_isbns / len(isbns) if isbns else 0
            
            if execution_times:
                metrics.avg_time_per_isbn = statistics.mean(execution_times)
                metrics.min_time = min(execution_times)
                metrics.max_time = max(execution_times)
            
            logger.info(f"–ù–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞: —É—Å–ø–µ—à–Ω–æ {successful}/{len(isbns)} ISBN –∑–∞ {metrics.total_time:.2f} —Å–µ–∫")
            
        except ImportError as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—É—é —Å–∏—Å—Ç–µ–º—É: {e}")
            metrics.error_rate = 1.0
            metrics.total_time = time.time() - start_time
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–µ: {e}")
            metrics.error_rate = 1.0
            metrics.total_time = time.time() - start_time
        
        return metrics
    
    def compare_results(self, legacy_metrics: TestMetrics, new_metrics: TestMetrics) -> Dict[str, Any]:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–≤—É—Ö —Å–∏—Å—Ç–µ–º.
        
        Args:
            legacy_metrics: –ú–µ—Ç—Ä–∏–∫–∏ —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º—ã
            new_metrics: –ú–µ—Ç—Ä–∏–∫–∏ –Ω–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        """
        comparison = {}
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
        comparison["legacy_success_rate"] = legacy_metrics.successful_isbns / legacy_metrics.total_isbns if legacy_metrics.total_isbns > 0 else 0
        comparison["new_success_rate"] = new_metrics.successful_isbns / new_metrics.total_isbns if new_metrics.total_isbns > 0 else 0
        comparison["success_rate_diff"] = comparison["new_success_rate"] - comparison["legacy_success_rate"]
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        comparison["legacy_avg_time"] = legacy_metrics.avg_time_per_isbn
        comparison["new_avg_time"] = new_metrics.avg_time_per_isbn
        comparison["performance_improvement"] = (legacy_metrics.avg_time_per_isbn - new_metrics.avg_time_per_isbn) / legacy_metrics.avg_time_per_isbn if legacy_metrics.avg_time_per_isbn > 0 else 0
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—à–∏–±–æ–∫
        comparison["legacy_error_rate"] = legacy_metrics.error_rate
        comparison["new_error_rate"] = new_metrics.error_rate
        comparison["error_rate_improvement"] = legacy_metrics.error_rate - new_metrics.error_rate
        
        # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
        comparison["overall_improvement"] = (
            comparison["performance_improvement"] * 0.5 +
            comparison["success_rate_diff"] * 0.3 +
            (-comparison["error_rate_improvement"]) * 0.2
        )
        
        return comparison
    
    async def run_full_pipeline(self) -> ABTestResult:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        logger.info("=" * 60)
        logger.info("–ó–ê–ü–£–°–ö –†–ï–ê–õ–¨–ù–û–ì–û A/B –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
        logger.info("=" * 60)
        
        # –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ISBN –∏–∑ PDF
        isbns = self.extract_isbns_from_pdfs()
        
        if not isbns:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ISBN –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return self.results
        
        logger.info(f"–î–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ {len(isbns)} ISBN")
        
        # –®–∞–≥ 2: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –æ–±–µ–∏—Ö —Å–∏—Å—Ç–µ–º
        legacy_task = asyncio.create_task(self.run_legacy_system(isbns))
        new_task = asyncio.create_task(self.run_new_system(isbns))
        
        legacy_metrics, new_metrics = await asyncio.gather(legacy_task, new_task)
        
        # –®–∞–≥ 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        comparison = self.compare_results(legacy_metrics, new_metrics)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.results.legacy_metrics = legacy_metrics
        self.results.new_metrics = new_metrics
        self.results.comparison = comparison
        
        # –®–∞–≥ 4: –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.print_results()
        
        return self.results
    
    def print_results(self):
        """–í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."""
        print("\n" + "=" * 80)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –†–ï–ê–õ–¨–ù–û–ì–û A/B –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
        print("=" * 80)
        
        print(f"\nüìö –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø:")
        print(f"   –í—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {self.results.timestamp}")
        print(f"   –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ ISBN: {len(self.results.isbns_used)}")
        print(f"   –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ ISBN: {', '.join(self.results.isbns_used[:5])}{'...' if len(self.results.isbns_used) > 5 else ''}")
        
        print(f"\nüèÅ –°–¢–ê–†–ê–Ø –°–ò–°–¢–ï–ú–ê:")
        legacy = self.results.legacy_metrics
        print(f"   –£—Å–ø–µ—à–Ω–æ: {legacy.successful_isbns}/{legacy.total_isbns} ({legacy.successful_isbns/legacy.total_isbns:.1%})")
        print(f"   –û—à–∏–±–∫–∏: {legacy.failed_isbns} ({legacy.error_rate:.1%})")
        print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {legacy.total_time:.2f} —Å–µ–∫")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ ISBN: {legacy.avg_time_per_isbn:.2f} —Å–µ–∫")
        
        print(f"\nüöÄ –ù–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê:")
        new = self.results.new_metrics
        print(f"   –£—Å–ø–µ—à–Ω–æ: {new.successful_isbns}/{new.total_isbns} ({new.successful_isbns/new.total_isbns:.1%})")
        print(f"   –û—à–∏–±–∫–∏: {new.failed_isbns} ({new.error_rate:.1%})")
        print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {new.total_time:.2f} —Å–µ–∫")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ ISBN: {new.avg_time_per_isbn:.2f} —Å–µ–∫")
        
        print(f"\nüìà –°–†–ê–í–ù–ï–ù–ò–ï:")
        comp = self.results.comparison
        print(f"   –£–ª—É—á—à–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏: {comp.get('success_rate_diff', 0):+.1%}")
        print(f"   –£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {comp.get('performance_improvement', 0):+.1%}")
        print(f"   –£–ª—É—á—à–µ–Ω–∏–µ –æ—à–∏–±–æ–∫: {comp.get('error_rate_improvement', 0):+.1%}")
        print(f"   –û–±—â–µ–µ —É–ª—É—á—à–µ–Ω–∏–µ: {comp.get('overall_improvement', 0):+.1%}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
        print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø:")
        if comp.get('overall_improvement', 0) > 0:
            print("   ‚úÖ –ù–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏–µ. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –Ω–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É.")
        else:
            print("   ‚ö†Ô∏è  –ù–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä–æ–π —Å–∏—Å—Ç–µ–º—ã.")